{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94acffde-a523-4bc6-9fd7-d6c0487fbe02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 7681.88it/s]\n",
      "\u001b[32m2025-03-10 13:57:50.674\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcrandata.chrom_io\u001b[0m:\u001b[36mimport_bigwigs\u001b[0m:\u001b[36m417\u001b[0m - \u001b[1mExtracting values from 1 bigWig files...\u001b[0m\n",
      "1it [00:00, 93.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added Hi-C contact data to adata.varp['hic_contacts']:\n",
      "Shape: (3, 3, 1)\n",
      "<xarray.DataArray (var_0: 3, var_1: 3, hic_file: 1)> Size: 140B\n",
      "<COO: shape=(3, 3, 1), dtype=float32, nnz=5, fill_value=0.0>\n",
      "Coordinates:\n",
      "  * var_0     (var_0) object 24B 'chr1:100-200' 'chr1:300-400' 'chr1:350-450'\n",
      "  * var_1     (var_1) object 24B 'chr1:100-200' 'chr1:300-400' 'chr1:350-450'\n",
      "  * hic_file  (hic_file) int64 8B 0\n",
      "\n",
      "Directory contents: ['beds', 'bigwigs', 'chrom.sizes', 'consensus.bed', 'chrom_data.h5', 'synthetic.bedp', 'adata.h5']\n",
      "\n",
      "Loaded CrAnData from HDF5:\n",
      "CrAnData object with 1 observations and 3 variables\n",
      "obs:\n",
      "                                            file_path\n",
      "test  /scratch/fast/46144/tmpjwrhoucu/bigwigs/test.bw\n",
      "var:\n",
      "             chrom  start  end  chunk_index   chr\n",
      "region                                           \n",
      "chr1:100-200  chr1    100  200            0  chr1\n",
      "chr1:300-400  chr1    300  400            0  chr1\n",
      "chr1:350-450  chr1    350  450            0  chr1\n",
      "varp keys: ['hic_contacts']\n",
      "Hi-C contact data shape: (3, 3, 1)\n",
      "<xarray.DataArray (var_0: 3, var_1: 3, hic_file: 1)> Size: 140B\n",
      "<COO: shape=(3, 3, 1), dtype=float32, nnz=5, fill_value=0.0>\n",
      "Dimensions without coordinates: var_0, var_1, hic_file\n",
      "2025-03-10T13:58:02.423373-0700 INFO Loading sequences into memory...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 12774.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-10T13:58:02.434586-0700 INFO Loading sequences into memory...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 3/3 [00:00<00:00, 16426.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-10T13:58:02.447068-0700 INFO Loading sequences into memory...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 3/3 [00:00<00:00, 13386.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-10T13:58:02.458052-0700 INFO Loading sequences into memory...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 3/3 [00:00<00:00, 4529.49it/s]\n",
      "/home/matthew.schmitz/Matthew/utils/miniforge3/envs/crested/lib/python3.12/site-packages/torch/utils/data/sampler.py:76: UserWarning: `data_source` argument is not used and will be removed in 2.2.0.You may still have custom implementation that utilizes it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iterating over a couple of training batches from MetaAnnDataModule:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:01<00:00,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta Batch 0:\n",
      "  sequence: shape torch.Size([100, 3, 4])\n",
      "  y: shape torch.Size([1, 3, 100])\n",
      "  hic: shape torch.Size([1, 3, 1])\n",
      "  gex: shape torch.Size([1, 3, 100])\n",
      "Meta Batch 1:\n",
      "  sequence: shape torch.Size([100, 3, 4])\n",
      "  y: shape torch.Size([1, 3, 100])\n",
      "  hic: shape torch.Size([1, 3, 1])\n",
      "  gex: shape torch.Size([1, 3, 100])\n",
      "Meta Batch 2:\n",
      "  sequence: shape torch.Size([100, 3, 4])\n",
      "  y: shape torch.Size([1, 3, 100])\n",
      "  hic: shape torch.Size([1, 3, 1])\n",
      "  gex: shape torch.Size([1, 3, 100])\n",
      "Meta Batch 3:\n",
      "  sequence: shape torch.Size([100, 1, 4])\n",
      "  y: shape torch.Size([1, 1, 100])\n",
      "  hic: shape torch.Size([1, 1, 1])\n",
      "  gex: shape torch.Size([1, 1, 100])\n",
      "['beds', 'bigwigs', 'chrom.sizes', 'consensus.bed', 'chrom_data.h5', 'synthetic.bedp', 'adata.h5', 'chr1.fa', 'chr1.fa.fai']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyBigWig\n",
    "import importlib\n",
    "import xarray as xr\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "import crandata\n",
    "crandata = importlib.reload(crandata)\n",
    "\n",
    "\n",
    "import crandata\n",
    "import crandata.chrom_io\n",
    "crandata.crandata = importlib.reload(crandata.crandata)\n",
    "crandata.chrom_io = importlib.reload(crandata.chrom_io)\n",
    "crandata._anndatamodule = importlib.reload(crandata._anndatamodule)\n",
    "# crandata._dataloader = importlib.reload(crandata._dataloader)\n",
    "# crandata._dataset = importlib.reload(crandata._dataset)\n",
    "crandata._anndatamodule = importlib.reload(crandata._anndatamodule)\n",
    "from crandata._anndatamodule import MetaAnnDataModule\n",
    "\n",
    "# Create temporary directories for beds, bigwigs, etc.\n",
    "temp_dir = tempfile.TemporaryDirectory()\n",
    "base_dir = Path(temp_dir.name)\n",
    "beds_dir = base_dir / \"beds\"\n",
    "bigwigs_dir = base_dir / \"bigwigs\"\n",
    "beds_dir.mkdir(exist_ok=True)\n",
    "bigwigs_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Create a chromsizes file\n",
    "chromsizes_file = base_dir / \"chrom.sizes\"\n",
    "with open(chromsizes_file, \"w\") as f:\n",
    "    f.write(\"chr1\\t1000\\n\")\n",
    "\n",
    "# Create two BED files (ClassA and ClassB)\n",
    "bed_data_A = pd.DataFrame({0: [\"chr1\", \"chr1\"],\n",
    "                           1: [100, 300],\n",
    "                           2: [200, 400]})\n",
    "bed_data_B = pd.DataFrame({0: [\"chr1\", \"chr1\"],\n",
    "                           1: [150, 350],\n",
    "                           2: [250, 450]})\n",
    "bed_file_A = beds_dir / \"ClassA.bed\"\n",
    "bed_file_B = beds_dir / \"ClassB.bed\"\n",
    "bed_data_A.to_csv(bed_file_A, sep=\"\\t\", header=False, index=False)\n",
    "bed_data_B.to_csv(bed_file_B, sep=\"\\t\", header=False, index=False)\n",
    "\n",
    "# Create a consensus BED file\n",
    "consensus = pd.DataFrame({0: [\"chr1\", \"chr1\", \"chr1\"],\n",
    "                          1: [100, 300, 350],\n",
    "                          2: [200, 400, 450]})\n",
    "consensus_file = base_dir / \"consensus.bed\"\n",
    "consensus.to_csv(consensus_file, sep=\"\\t\", header=False, index=False)\n",
    "\n",
    "# Create a bigWig file with a single chromosome region\n",
    "bigwig_file = bigwigs_dir / \"test.bw\"\n",
    "bw = pyBigWig.open(str(bigwig_file), \"w\")\n",
    "bw.addHeader([(\"chr1\", 1000)])\n",
    "bw.addEntries(chroms=[\"chr1\"], starts=[0], ends=[1000], values=[5.0])\n",
    "bw.close()\n",
    "\n",
    "# Set parameters for extraction\n",
    "target_region_width = 100\n",
    "backed_path = os.path.join(base_dir, \"chrom_data.h5\")\n",
    "\n",
    "# Create the CrAnData object from the bigWig files and consensus regions\n",
    "adata = crandata.chrom_io.import_bigwigs(\n",
    "    bigwigs_folder=bigwigs_dir,\n",
    "    regions_file=consensus_file,\n",
    "    backed_path=backed_path,\n",
    "    target_region_width=target_region_width,\n",
    "    chromsizes_file=chromsizes_file,\n",
    "    \n",
    ")\n",
    "\n",
    "# Add a random obsm entry\n",
    "adata.obsm['gex'] = xr.DataArray(np.random.randn(adata.obs.shape[0], 100),\n",
    "                                 dims=['types', 'genes'])\n",
    "\n",
    "# Create a synthetic BEDP file for Hi-C contacts and add contacts to adata.varp\n",
    "synthetic_bedp = pd.DataFrame({\n",
    "    0: [\"chr1\", \"chr1\"],\n",
    "    1: [100, 300],\n",
    "    2: [200, 400],\n",
    "    3: [\"chr1\", \"chr1\"],\n",
    "    4: [150, 350],\n",
    "    5: [250, 450],\n",
    "    6: [10, 20]\n",
    "})\n",
    "synthetic_bedp_file = base_dir / \"synthetic.bedp\"\n",
    "synthetic_bedp.to_csv(synthetic_bedp_file, sep=\"\\t\", header=False, index=False)\n",
    "\n",
    "from crandata.chrom_io import add_contact_strengths_to_varp\n",
    "contacts = add_contact_strengths_to_varp(adata, [str(synthetic_bedp_file)], key=\"hic_contacts\")\n",
    "\n",
    "print(\"Added Hi-C contact data to adata.varp['hic_contacts']:\")\n",
    "print(\"Shape:\", adata.varp[\"hic_contacts\"].shape)\n",
    "print(adata.varp[\"hic_contacts\"])\n",
    "\n",
    "\n",
    "# Write to HDF5 and load back.\n",
    "h5_path = os.path.join(base_dir, \"adata.h5\")\n",
    "adata.to_h5(h5_path)\n",
    "adata_loaded = crandata.crandata.CrAnData.from_h5(h5_path,backed=['X'])\n",
    "print(\"\\nDirectory contents:\", os.listdir(base_dir))\n",
    "print(\"\\nLoaded CrAnData from HDF5:\")\n",
    "print(adata_loaded)\n",
    "print(\"obs:\")\n",
    "print(adata_loaded.obs)\n",
    "print(\"var:\")\n",
    "print(adata_loaded.var)\n",
    "print(\"varp keys:\", list(adata_loaded.varp.keys()))\n",
    "if \"hic_contacts\" in adata_loaded.varp:\n",
    "    print(\"Hi-C contact data shape:\", adata_loaded.varp[\"hic_contacts\"].shape)\n",
    "    print(adata_loaded.varp[\"hic_contacts\"])\n",
    "\n",
    "\n",
    "# Create two copies of the loaded CrAnData (simulate two different datasets/species)\n",
    "adata1 = adata_loaded.copy()\n",
    "adata2 = adata_loaded.copy()\n",
    "# Ensure each has a 'split' column\n",
    "adata1.var[\"split\"] = \"train\"\n",
    "adata2.var[\"split\"] = \"train\"\n",
    "\n",
    "# Create a dummy FASTA file for the genome (with a single record for chr1)\n",
    "fasta_file = base_dir / \"chr1.fa\"\n",
    "with open(fasta_file, \"w\") as f:\n",
    "    f.write(\">chr1\\n\")\n",
    "    f.write(\"A\" * 1000 + \"\\n\")\n",
    "\n",
    "# Instead of passing a string, create a Genome object.\n",
    "from crandata._genome import Genome\n",
    "dummy_genome = Genome(str(fasta_file), chrom_sizes=str(chromsizes_file))\n",
    "\n",
    "# Import MetaAnnDataModule (using the package name so that relative imports resolve)\n",
    "\n",
    "\n",
    "# Instantiate MetaAnnDataModule with the two datasets and corresponding genomes.\n",
    "meta_module = MetaAnnDataModule(\n",
    "    adatas=[adata1, adata2],\n",
    "    genomes=[dummy_genome, dummy_genome],\n",
    "    data_sources={'y': 'X','hic':'varp/hic_contacts','gex':'obsm/gex'},\n",
    "    in_memory=True,\n",
    "    random_reverse_complement=True,\n",
    "    max_stochastic_shift=5,\n",
    "    deterministic_shift=False,\n",
    "    shuffle_obs=True,\n",
    "    shuffle=True,\n",
    "    batch_size=3,    # small batch size for testing\n",
    "    epoch_size=10    # small epoch size for quick testing\n",
    ")\n",
    "\n",
    "# Setup the meta module for the \"fit\" stage (train/val)\n",
    "meta_module.setup(\"fit\")\n",
    "\n",
    "# Retrieve the training dataloader from the meta module and iterate over a couple of batches.\n",
    "meta_train_dl = meta_module.train_dataloader\n",
    "\n",
    "print(\"\\nIterating over a couple of training batches from MetaAnnDataModule:\")\n",
    "for i, batch in enumerate(tqdm.tqdm(meta_train_dl.data)):\n",
    "    print(f\"Meta Batch {i}:\")\n",
    "    for key, tensor in batch.items():\n",
    "        print(f\"  {key}: shape {tensor.shape}\")\n",
    "    # if i == 1:\n",
    "    #     break\n",
    "\n",
    "print(os.listdir(base_dir))\n",
    "\n",
    "temp_dir.cleanup()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90ebbd33-d888-4bee-a9b7-93743886288e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta Batch 0:\n",
      "  sequence: shape torch.Size([100, 3, 4])\n",
      "  y: shape torch.Size([1, 3, 100])\n",
      "  hic: shape torch.Size([1, 3, 1])\n",
      "  gex: shape torch.Size([1, 3, 100])\n",
      "Meta Batch 1:\n",
      "  sequence: shape torch.Size([100, 3, 4])\n",
      "  y: shape torch.Size([1, 3, 100])\n",
      "  hic: shape torch.Size([1, 3, 1])\n",
      "  gex: shape torch.Size([1, 3, 100])\n",
      "Meta Batch 2:\n",
      "  sequence: shape torch.Size([100, 3, 4])\n",
      "  y: shape torch.Size([1, 3, 100])\n",
      "  hic: shape torch.Size([1, 3, 1])\n",
      "  gex: shape torch.Size([1, 3, 100])\n",
      "Meta Batch 3:\n",
      "  sequence: shape torch.Size([100, 1, 4])\n",
      "  y: shape torch.Size([1, 1, 100])\n",
      "  hic: shape torch.Size([1, 1, 1])\n",
      "  gex: shape torch.Size([1, 1, 100])\n",
      "         19904 function calls (19690 primitive calls) in 0.024 seconds\n",
      "\n",
      "   Ordered by: standard name\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "       10    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:1128(find_spec)\n",
      "       60    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:1222(__enter__)\n",
      "       60    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:1226(__exit__)\n",
      "       10    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:124(setdefault)\n",
      "       10    0.000    0.000    0.003    0.000 <frozen importlib._bootstrap>:1240(_find_spec)\n",
      "       10    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:1285(_sanity_check)\n",
      "       10    0.000    0.000    0.003    0.000 <frozen importlib._bootstrap>:1304(_find_and_load_unlocked)\n",
      "       10    0.000    0.000    0.004    0.000 <frozen importlib._bootstrap>:1349(_find_and_load)\n",
      "       10    0.000    0.000    0.004    0.000 <frozen importlib._bootstrap>:1375(_gcd_import)\n",
      "        7    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:1390(_handle_fromlist)\n",
      "       10    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:158(__init__)\n",
      "       10    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:162(__enter__)\n",
      "       10    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:173(__exit__)\n",
      "       10    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:232(__init__)\n",
      "       10    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:304(acquire)\n",
      "       10    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:372(release)\n",
      "       10    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:412(__init__)\n",
      "       10    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:416(__enter__)\n",
      "       10    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:420(__exit__)\n",
      "       10    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:426(_get_module_lock)\n",
      "       10    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:445(cb)\n",
      "       10    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:480(_call_with_frames_removed)\n",
      "      550    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:491(_verbose_message)\n",
      "       10    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:599(__init__)\n",
      "       20    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:645(parent)\n",
      "       10    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:74(__new__)\n",
      "       10    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:79(__init__)\n",
      "       10    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:82(remove)\n",
      "       10    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:982(find_spec)\n",
      "      550    0.001    0.000    0.001    0.000 <frozen importlib._bootstrap_external>:126(_path_join)\n",
      "      110    0.000    0.000    0.001    0.000 <frozen importlib._bootstrap_external>:140(_path_stat)\n",
      "      130    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:1469(_path_importer_cache)\n",
      "       10    0.000    0.000    0.003    0.000 <frozen importlib._bootstrap_external>:1491(_get_spec)\n",
      "       10    0.000    0.000    0.003    0.000 <frozen importlib._bootstrap_external>:1520(find_spec)\n",
      "      110    0.001    0.000    0.003    0.000 <frozen importlib._bootstrap_external>:1593(find_spec)\n",
      "      110    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:71(_relax_case)\n",
      "      2/1    0.000    0.000    0.023    0.023 <string>:1(<module>)\n",
      "       10    0.000    0.000    0.000    0.000 __editable___crandata_0_1_finder.py:15(find_spec)\n",
      "       10    0.000    0.000    0.000    0.000 __editable___crandata_0_1_finder.py:61(find_spec)\n",
      "       10    0.000    0.000    0.000    0.000 __init__.py:101(find_spec)\n",
      "       10    0.000    0.000    0.000    0.000 __init__.py:108(<lambda>)\n",
      "        5    0.000    0.000    0.000    0.000 __init__.py:128(annotate)\n",
      "        1    0.000    0.000    0.000    0.000 __init__.py:14(is_available)\n",
      "       20    0.000    0.000    0.000    0.000 __init__.py:164(match)\n",
      "       20    0.000    0.000    0.000    0.000 __init__.py:174(search)\n",
      "       40    0.000    0.000    0.000    0.000 __init__.py:280(_compile)\n",
      "       10    0.000    0.000    0.004    0.000 __init__.py:73(import_module)\n",
      "        1    0.000    0.000    0.000    0.000 _collections_abc.py:804(get)\n",
      "       11    0.002    0.000    0.002    0.000 _dataloader.py:166(__iter__)\n",
      "        4    0.001    0.000    0.003    0.001 _dataloader.py:273(batch_collate_fn)\n",
      "       32    0.000    0.000    0.000    0.000 _dataloader.py:292(<genexpr>)\n",
      "        1    0.000    0.000    0.000    0.000 _dataloader.py:354(_create_dataset)\n",
      "        1    0.000    0.000    0.000    0.000 _dataloader.py:390(data)\n",
      "       10    0.000    0.000    0.015    0.001 _dataset.py:257(__getitem__)\n",
      "       20    0.000    0.000    0.014    0.001 _dataset.py:285(_get_data_array)\n",
      "       10    0.000    0.000    0.015    0.001 _dataset.py:365(__getitem__)\n",
      "        5    0.000    0.000    0.000    0.000 _dataset.py:95(_reverse_complement)\n",
      "       10    0.000    0.000    0.000    0.000 _dataset.py:98(get_sequence)\n",
      "        5    0.000    0.000    0.000    0.000 _jit_internal.py:103(is_scripting)\n",
      "       40    0.000    0.000    0.000    0.000 _methods.py:50(_sum)\n",
      "        5    0.000    0.000    0.000    0.000 _ops.py:1105(__call__)\n",
      "        5    0.000    0.000    0.000    0.000 _ops.py:939(__call__)\n",
      "        5    0.000    0.000    0.000    0.000 _ops.py:993(_must_dispatch_in_python)\n",
      "        5    0.000    0.000    0.000    0.000 _ops.py:995(<lambda>)\n",
      "        5    0.000    0.000    0.000    0.000 _pytree.py:1197(tree_any)\n",
      "       10    0.000    0.000    0.000    0.000 _pytree.py:411(_tuple_flatten)\n",
      "        5    0.000    0.000    0.000    0.000 _pytree.py:439(_dict_flatten)\n",
      "       35    0.000    0.000    0.000    0.000 _pytree.py:654(_is_namedtuple_instance)\n",
      "       35    0.000    0.000    0.000    0.000 _pytree.py:665(_get_node_type)\n",
      "       20    0.000    0.000    0.000    0.000 _pytree.py:672(_is_leaf)\n",
      "    35/10    0.000    0.000    0.000    0.000 _pytree.py:890(tree_iter)\n",
      "       10    0.000    0.000    0.001    0.000 _slicing.py:11(normalize_index)\n",
      "       30    0.000    0.000    0.000    0.000 _slicing.py:135(sanitize_index)\n",
      "       70    0.000    0.000    0.000    0.000 _slicing.py:181(_sanitize_index_element)\n",
      "    40/10    0.000    0.000    0.000    0.000 _slicing.py:189(posify_index)\n",
      "       30    0.000    0.000    0.000    0.000 _slicing.py:226(clip_slice)\n",
      "       30    0.000    0.000    0.000    0.000 _slicing.py:265(replace_none)\n",
      "       10    0.000    0.000    0.000    0.000 _slicing.py:65(replace_ellipsis)\n",
      "       30    0.000    0.000    0.000    0.000 _slicing.py:84(check_index)\n",
      "       10    0.000    0.000    0.000    0.000 _sparse_array.py:33(__init__)\n",
      "       30    0.000    0.000    0.000    0.000 _sparse_array.py:37(<genexpr>)\n",
      "       30    0.000    0.000    0.000    0.000 _sparse_array.py:40(<genexpr>)\n",
      "       80    0.000    0.000    0.000    0.000 _sparse_array.py:84(ndim)\n",
      "       10    0.000    0.000    0.000    0.000 _version.py:114(_compare)\n",
      "       10    0.000    0.000    0.000    0.000 _version.py:151(__ge__)\n",
      "       20    0.000    0.000    0.000    0.000 _version.py:55(__init__)\n",
      "       10    0.000    0.000    0.000    0.000 _version.py:78(_compare_version)\n",
      "       10    0.000    0.000    0.000    0.000 _version.py:99(_compare_pre_release)\n",
      "      176    0.000    0.000    0.000    0.000 abc.py:117(__instancecheck__)\n",
      "       63    0.000    0.000    0.000    0.000 abc.py:121(__subclasscheck__)\n",
      "        2    0.000    0.000    0.001    0.000 asyncio.py:200(_handle_events)\n",
      "        1    0.000    0.000    0.000    0.000 asyncio.py:210(call_at)\n",
      "        1    0.000    0.000    0.000    0.000 asyncio.py:225(add_callback)\n",
      "        6    0.000    0.000    0.000    0.000 attrsettr.py:43(__getattr__)\n",
      "        6    0.000    0.000    0.000    0.000 attrsettr.py:66(_get_attr_opt)\n",
      "       20    0.000    0.000    0.000    0.000 base.py:1671(name)\n",
      "       20    0.000    0.000    0.000    0.000 base.py:5373(__getitem__)\n",
      "       10    0.000    0.000    0.000    0.000 base.py:5425(_getitem_slice)\n",
      "       10    0.000    0.000    0.000    0.000 base.py:649(_simple_new)\n",
      "       10    0.000    0.000    0.000    0.000 base.py:831(_reset_identity)\n",
      "       40    0.000    0.000    0.000    0.000 base.py:909(__len__)\n",
      "        4    0.000    0.000    0.000    0.000 base.py:915(__array__)\n",
      "       10    0.000    0.000    0.000    0.000 base.py:974(dtype)\n",
      "        2    0.000    0.000    0.000    0.000 base_events.py:1894(_add_callback)\n",
      "        2    0.000    0.000    0.000    0.000 base_events.py:1909(_run_once)\n",
      "        2    0.000    0.000    0.000    0.000 base_events.py:2004(get_debug)\n",
      "        2    0.000    0.000    0.000    0.000 base_events.py:539(_check_closed)\n",
      "        6    0.000    0.000    0.000    0.000 base_events.py:734(time)\n",
      "        1    0.000    0.000    0.000    0.000 base_events.py:743(call_later)\n",
      "        1    0.000    0.000    0.000    0.000 base_events.py:767(call_at)\n",
      "        1    0.000    0.000    0.000    0.000 base_events.py:785(call_soon)\n",
      "        1    0.000    0.000    0.000    0.000 base_events.py:814(_call_soon)\n",
      "       10    0.000    0.000    0.004    0.000 cftimeindex.py:160(assert_all_valid_date_type)\n",
      "       10    0.000    0.000    0.004    0.000 cftimeindex.py:260(__new__)\n",
      "       10    0.000    0.000    0.000    0.000 common.py:152(cast_scalar_indexer)\n",
      "       10    0.000    0.000    0.000    0.000 common.py:165(__array__)\n",
      "       20    0.000    0.000    0.000    0.000 common.py:298(__getattr__)\n",
      "      200    0.000    0.000    0.000    0.000 common.py:327(__setattr__)\n",
      "       60    0.000    0.000    0.000    0.000 contextlib.py:440(__init__)\n",
      "       60    0.000    0.000    0.000    0.000 contextlib.py:443(__enter__)\n",
      "       60    0.000    0.000    0.000    0.000 contextlib.py:446(__exit__)\n",
      "       40    0.000    0.000    0.000    0.000 coordinates.py:904(__init__)\n",
      "       70    0.000    0.000    0.000    0.000 copy.py:102(_copy_immutable)\n",
      "       80    0.000    0.000    0.000    0.000 copy.py:61(copy)\n",
      "       10    0.000    0.000    0.000    0.000 core.py:199(__init__)\n",
      "       60    0.000    0.000    0.000    0.000 core.py:257(__init__)\n",
      "       10    0.000    0.000    0.000    0.000 core.py:392(todense)\n",
      "      150    0.000    0.000    0.000    0.000 core.py:407(ndim)\n",
      "      150    0.000    0.000    0.000    0.000 core.py:449(shape)\n",
      "      290    0.000    0.000    0.000    0.000 core.py:496(dims)\n",
      "       60    0.000    0.000    0.000    0.000 core.py:505(_parse_dimensions)\n",
      "       50    0.000    0.000    0.000    0.000 core.py:524(attrs)\n",
      "       80    0.000    0.000    0.000    0.000 core.py:552(dtype)\n",
      "       30    0.000    0.000    0.010    0.000 crandata.py:259(index_dim)\n",
      "       20    0.000    0.000    0.000    0.000 crandata.py:267(__init__)\n",
      "       10    0.000    0.000    0.000    0.000 crandata.py:270(data)\n",
      "       10    0.000    0.000    0.010    0.001 crandata.py:277(__getitem__)\n",
      "       20    0.000    0.000    0.000    0.000 crandata.py:354(X)\n",
      "        4    0.000    0.000    0.000    0.000 crandata.py:364(obs)\n",
      "       10    0.000    0.000    0.000    0.000 crandata.py:380(obsm)\n",
      "       30    0.000    0.000    0.000    0.000 crandata.py:396(varp)\n",
      "       10    0.000    0.000    0.000    0.000 crandata.py:48(reindex_obs_array)\n",
      "       40    0.000    0.000    0.000    0.000 dataarray.py:1002(coords)\n",
      "       40    0.000    0.000    0.013    0.000 dataarray.py:1468(isel)\n",
      "      100    0.000    0.000    0.000    0.000 dataarray.py:1537(<genexpr>)\n",
      "       40    0.000    0.000    0.000    0.000 dataarray.py:437(__init__)\n",
      "       40    0.000    0.000    0.000    0.000 dataarray.py:520(_replace)\n",
      "       40    0.000    0.000    0.000    0.000 dataarray.py:709(name)\n",
      "      210    0.000    0.000    0.000    0.000 dataarray.py:718(variable)\n",
      "       30    0.000    0.000    0.000    0.000 dataarray.py:769(ndim)\n",
      "       80    0.000    0.000    0.000    0.000 dataarray.py:783(data)\n",
      "       20    0.000    0.000    0.000    0.000 dataarray.py:801(values)\n",
      "       40    0.000    0.000    0.000    0.000 dataarray.py:860(dims)\n",
      "       10    0.000    0.000    0.000    0.000 dataarray.py:882(_item_key_to_dict)\n",
      "       10    0.000    0.000    0.004    0.000 dataarray.py:899(__getitem__)\n",
      "       80    0.000    0.000    0.000    0.000 dataarray.py:927(_attr_sources)\n",
      "       60    0.000    0.000    0.000    0.000 dataarray.py:933(_item_sources)\n",
      "       40    0.000    0.000    0.000    0.000 dataarray.py:949(attrs)\n",
      "       40    0.000    0.000    0.000    0.000 dataarray.py:995(xindexes)\n",
      "        1    0.000    0.000    0.000    0.000 dataloader.py:232(__init__)\n",
      "        1    0.001    0.001    0.001    0.001 dataloader.py:410(_get_iterator)\n",
      "        1    0.000    0.000    0.000    0.000 dataloader.py:421(multiprocessing_context)\n",
      "    20/19    0.000    0.000    0.000    0.000 dataloader.py:454(__setattr__)\n",
      "        1    0.000    0.000    0.001    0.001 dataloader.py:471(__iter__)\n",
      "        2    0.000    0.000    0.000    0.000 dataloader.py:486(_auto_collation)\n",
      "        1    0.000    0.000    0.000    0.000 dataloader.py:490(_index_sampler)\n",
      "        1    0.000    0.000    0.000    0.000 dataloader.py:534(check_worker_number_rationality)\n",
      "        1    0.000    0.000    0.000    0.000 dataloader.py:625(__init__)\n",
      "        5    0.000    0.000    0.002    0.000 dataloader.py:690(_next_index)\n",
      "        5    0.000    0.000    0.029    0.006 dataloader.py:696(__next__)\n",
      "        1    0.000    0.000    0.000    0.000 dataloader.py:734(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 dataloader.py:74(create_fetcher)\n",
      "        5    0.000    0.000    0.029    0.006 dataloader.py:755(_next_data)\n",
      "        1    0.000    0.000    0.000    0.000 dataloader.py:97(_get_distributed_settings)\n",
      "        1    0.000    0.000    0.000    0.000 decorator.py:199(fix)\n",
      "        1    0.000    0.000    0.005    0.005 decorator.py:229(fun)\n",
      "        1    0.000    0.000    0.000    0.000 distributed_c10d.py:1121(is_initialized)\n",
      "        1    0.000    0.000    0.000    0.000 distributed_c10d.py:576(default_pg)\n",
      "        1    0.000    0.000    0.000    0.000 distributed_c10d.py:705(WORLD)\n",
      "       33    0.000    0.000    0.000    0.000 enum.py:1129(__new__)\n",
      "       72    0.000    0.000    0.000    0.000 enum.py:1544(_get_value)\n",
      "       15    0.000    0.000    0.000    0.000 enum.py:1551(__or__)\n",
      "        9    0.000    0.000    0.000    0.000 enum.py:1562(__and__)\n",
      "       33    0.000    0.000    0.000    0.000 enum.py:726(__call__)\n",
      "        1    0.000    0.000    0.000    0.000 events.py:111(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 events.py:127(__lt__)\n",
      "        2    0.000    0.000    0.000    0.000 events.py:36(__init__)\n",
      "        3    0.000    0.000    0.001    0.000 events.py:86(_run)\n",
      "        4    0.000    0.000    0.019    0.005 fetch.py:47(fetch)\n",
      "        1    0.000    0.000    0.000    0.000 fetch.py:9(__init__)\n",
      "       60    0.000    0.000    0.000    0.000 getlimits.py:487(__new__)\n",
      "        1    0.000    0.000    0.004    0.004 history.py:55(only_when_enabled)\n",
      "        1    0.000    0.000    0.000    0.000 history.py:833(_writeout_input_cache)\n",
      "        1    0.000    0.000    0.000    0.000 history.py:839(_writeout_output_cache)\n",
      "        1    0.000    0.000    0.000    0.000 history.py:845(writeout_cache)\n",
      "       40    0.000    0.000    0.000    0.000 indexes.py:1460(__init__)\n",
      "       90    0.000    0.000    0.000    0.000 indexes.py:1491(<genexpr>)\n",
      "       40    0.000    0.000    0.005    0.000 indexes.py:1813(_apply_indexes_fast)\n",
      "       40    0.000    0.000    0.005    0.000 indexes.py:1867(isel_indexes)\n",
      "       90    0.000    0.000    0.000    0.000 indexes.py:1874(<genexpr>)\n",
      "       10    0.000    0.000    0.004    0.000 indexes.py:420(_maybe_cast_to_cftimeindex)\n",
      "       10    0.000    0.000    0.004    0.000 indexes.py:432(safe_cast_to_index)\n",
      "       10    0.000    0.000    0.000    0.000 indexes.py:578(__init__)\n",
      "       10    0.000    0.000    0.000    0.000 indexes.py:605(_replace)\n",
      "       10    0.000    0.000    0.004    0.000 indexes.py:703(create_variables)\n",
      "       20    0.000    0.000    0.000    0.000 indexes.py:727(isel)\n",
      "       50    0.000    0.000    0.003    0.000 indexing.py:1021(apply_indexer)\n",
      "       10    0.000    0.000    0.002    0.000 indexing.py:12(getitem)\n",
      "       10    0.000    0.000    0.000    0.000 indexing.py:136(_mask)\n",
      "       60    0.000    0.000    0.000    0.000 indexing.py:1471(is_fancy_indexer)\n",
      "       30    0.000    0.000    0.000    0.000 indexing.py:1489(__init__)\n",
      "       30    0.000    0.000    0.000    0.000 indexing.py:1510(__getitem__)\n",
      "       10    0.000    0.000    0.000    0.000 indexing.py:1568(__init__)\n",
      "       10    0.000    0.000    0.002    0.000 indexing.py:1587(__getitem__)\n",
      "       10    0.000    0.000    0.004    0.000 indexing.py:1712(__init__)\n",
      "       10    0.000    0.000    0.000    0.000 indexing.py:1722(dtype)\n",
      "       30    0.000    0.000    0.000    0.000 indexing.py:1745(shape)\n",
      "       10    0.000    0.000    0.000    0.000 indexing.py:1749(_convert_scalar)\n",
      "       10    0.000    0.000    0.000    0.000 indexing.py:1771(_prepare_key)\n",
      "       10    0.000    0.000    0.000    0.000 indexing.py:1779(_handle_result)\n",
      "       10    0.000    0.000    0.000    0.000 indexing.py:179(_ind_ar_from_indices)\n",
      "       10    0.000    0.000    0.000    0.000 indexing.py:1832(__getitem__)\n",
      "       60    0.000    0.000    0.000    0.000 indexing.py:212(expanded_indexer)\n",
      "       10    0.000    0.000    0.000    0.000 indexing.py:213(_prune_indices)\n",
      "       10    0.000    0.000    0.000    0.000 indexing.py:259(_separate_adv_indices)\n",
      "       50    0.000    0.000    0.000    0.000 indexing.py:330(__init__)\n",
      "       50    0.000    0.000    0.000    0.000 indexing.py:335(tuple)\n",
      "      270    0.000    0.000    0.000    0.000 indexing.py:347(as_integer_or_none)\n",
      "       90    0.000    0.000    0.000    0.000 indexing.py:351(as_integer_slice)\n",
      "       50    0.000    0.000    0.001    0.000 indexing.py:390(__init__)\n",
      "       40    0.000    0.000    0.000    0.000 indexing.py:544(_check_and_raise_if_non_basic_indexer)\n",
      "       20    0.000    0.000    0.000    0.000 indexing.py:68(<genexpr>)\n",
      "       50    0.000    0.000    0.000    0.000 indexing.py:862(as_indexable)\n",
      "        4    0.000    0.000    0.000    0.000 inspect.py:2792(name)\n",
      "       10    0.000    0.000    0.000    0.000 inspect.py:2804(kind)\n",
      "        1    0.000    0.000    0.000    0.000 inspect.py:2884(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 inspect.py:2892(args)\n",
      "        1    0.000    0.000    0.000    0.000 inspect.py:2915(kwargs)\n",
      "        1    0.000    0.000    0.000    0.000 inspect.py:2945(apply_defaults)\n",
      "        4    0.000    0.000    0.000    0.000 inspect.py:3085(parameters)\n",
      "        1    0.000    0.000    0.000    0.000 inspect.py:3129(_bind)\n",
      "        1    0.000    0.000    0.000    0.000 inspect.py:3268(bind)\n",
      "        2    0.000    0.000    0.000    0.000 ioloop.py:541(time)\n",
      "        1    0.000    0.000    0.000    0.000 ioloop.py:596(call_later)\n",
      "        1    0.000    0.000    0.000    0.000 ioloop.py:742(_run_callback)\n",
      "        1    0.000    0.000    0.000    0.000 iostream.py:138(_event_pipe)\n",
      "        3    0.000    0.000    0.000    0.000 iostream.py:157(_handle_event)\n",
      "        2    0.000    0.000    0.000    0.000 iostream.py:213(_is_master_process)\n",
      "        2    0.000    0.000    0.000    0.000 iostream.py:216(_check_mp_mode)\n",
      "        2    0.000    0.000    0.000    0.000 iostream.py:255(closed)\n",
      "        1    0.000    0.000    0.000    0.000 iostream.py:259(schedule)\n",
      "        2    0.000    0.000    0.000    0.000 iostream.py:276(<lambda>)\n",
      "        2    0.000    0.000    0.000    0.000 iostream.py:278(_really_send)\n",
      "       40    0.000    0.000    0.000    0.000 iostream.py:505(parent_header)\n",
      "       40    0.000    0.000    0.000    0.000 iostream.py:550(_is_master_process)\n",
      "       40    0.000    0.000    0.000    0.000 iostream.py:577(_schedule_flush)\n",
      "        1    0.000    0.000    0.000    0.000 iostream.py:587(_schedule_in_thread)\n",
      "       40    0.000    0.000    0.000    0.000 iostream.py:655(write)\n",
      "       20    0.000    0.000    0.000    0.000 multiarray.py:1089(copyto)\n",
      "       10    0.000    0.000    0.000    0.000 multiarray.py:161(concatenate)\n",
      "       10    0.000    0.000    0.000    0.000 multiarray.py:361(where)\n",
      "       10    0.000    0.000    0.000    0.000 numeric.py:1918(isscalar)\n",
      "       20    0.000    0.000    0.000    0.000 numeric.py:300(full)\n",
      "       60    0.000    0.000    0.000    0.000 numerictypes.py:288(issubclass_)\n",
      "       30    0.000    0.000    0.000    0.000 numerictypes.py:470(issubdtype)\n",
      "        1    0.000    0.000    0.000    0.000 os.py:709(__getitem__)\n",
      "        1    0.000    0.000    0.000    0.000 os.py:791(encode)\n",
      "        1    0.000    0.000    0.000    0.000 os.py:795(decode)\n",
      "        5    0.000    0.000    0.000    0.000 profiler.py:721(__init__)\n",
      "        5    0.000    0.000    0.000    0.000 profiler.py:732(__enter__)\n",
      "        5    0.000    0.000    0.000    0.000 profiler.py:738(__exit__)\n",
      "        3    0.000    0.000    0.000    0.000 queue.py:209(_qsize)\n",
      "        3    0.000    0.000    0.000    0.000 queue.py:97(empty)\n",
      "        1    0.000    0.000    0.000    0.000 sampler.py:309(__init__)\n",
      "        5    0.000    0.000    0.002    0.000 sampler.py:334(__iter__)\n",
      "        3    0.000    0.000    0.000    0.000 selector_events.py:750(_process_events)\n",
      "        2    0.000    0.000    0.000    0.000 selectors.py:275(_key_from_fd)\n",
      "        2    0.000    0.000    0.000    0.000 selectors.py:451(select)\n",
      "       10    0.000    0.000    0.000    0.000 serialize.py:30(_numba_unpickle)\n",
      "       10    0.000    0.000    0.000    0.000 shape_base.py:207(_arrays_for_stack_dispatcher)\n",
      "       10    0.000    0.000    0.000    0.000 shape_base.py:361(_stack_dispatcher)\n",
      "       10    0.000    0.000    0.000    0.000 shape_base.py:371(stack)\n",
      "       10    0.000    0.000    0.000    0.000 six.py:194(find_spec)\n",
      "       15    0.000    0.000    0.000    0.000 socket.py:626(send)\n",
      "        2    0.000    0.000    0.000    0.000 socket.py:703(send_multipart)\n",
      "        3    0.000    0.000    0.000    0.000 socket.py:774(recv_multipart)\n",
      "        1    0.000    0.000    0.000    0.000 threading.py:1155(_wait_for_tstate_lock)\n",
      "        1    0.000    0.000    0.000    0.000 threading.py:1222(is_alive)\n",
      "        2    0.000    0.000    0.000    0.000 threading.py:299(__enter__)\n",
      "        2    0.000    0.000    0.000    0.000 threading.py:302(__exit__)\n",
      "        1    0.000    0.000    0.000    0.000 threading.py:308(_release_save)\n",
      "        1    0.000    0.000    0.000    0.000 threading.py:311(_acquire_restore)\n",
      "        1    0.000    0.000    0.000    0.000 threading.py:314(_is_owned)\n",
      "        1    0.000    0.000    0.000    0.000 threading.py:601(is_set)\n",
      "        1    0.000    0.000    0.000    0.000 threading.py:627(clear)\n",
      "        1    0.000    0.000    0.000    0.000 traitlets.py:1512(_notify_trait)\n",
      "        1    0.000    0.000    0.000    0.000 traitlets.py:1523(notify_change)\n",
      "        1    0.000    0.000    0.000    0.000 traitlets.py:1527(_notify_observers)\n",
      "        2    0.000    0.000    0.000    0.000 traitlets.py:2304(validate)\n",
      "        2    0.000    0.000    0.000    0.000 traitlets.py:3474(validate)\n",
      "        2    0.000    0.000    0.000    0.000 traitlets.py:3486(validate_elements)\n",
      "        2    0.000    0.000    0.000    0.000 traitlets.py:3624(validate_elements)\n",
      "        2    0.000    0.000    0.000    0.000 traitlets.py:3631(set)\n",
      "        6    0.000    0.000    0.000    0.000 traitlets.py:629(get)\n",
      "        6    0.000    0.000    0.000    0.000 traitlets.py:676(__get__)\n",
      "        2    0.000    0.000    0.000    0.000 traitlets.py:689(set)\n",
      "        2    0.000    0.000    0.000    0.000 traitlets.py:708(__set__)\n",
      "        2    0.000    0.000    0.000    0.000 traitlets.py:718(_validate)\n",
      "        2    0.000    0.000    0.000    0.000 traitlets.py:727(_cross_validate)\n",
      "        3    0.000    0.000    0.000    0.000 typing.py:1221(__instancecheck__)\n",
      "        6    0.000    0.000    0.000    0.000 typing.py:1285(__hash__)\n",
      "        3    0.000    0.000    0.000    0.000 typing.py:1492(__subclasscheck__)\n",
      "       75    0.000    0.000    0.000    0.000 typing.py:2182(cast)\n",
      "       14    0.000    0.000    0.000    0.000 typing.py:392(inner)\n",
      "        1    0.000    0.000    0.000    0.000 tz.py:74(utcoffset)\n",
      "      150    0.000    0.000    0.000    0.000 utils.py:102(is_dict_like)\n",
      "       10    0.000    0.000    0.004    0.000 utils.py:1240(attempt_import)\n",
      "       90    0.000    0.000    0.000    0.000 utils.py:179(either_dict_or_kwargs)\n",
      "       10    0.000    0.000    0.000    0.000 utils.py:304(_is_scalar)\n",
      "       10    0.000    0.000    0.000    0.000 utils.py:320(is_scalar)\n",
      "       10    0.000    0.000    0.000    0.000 utils.py:337(to_0d_array)\n",
      "       10    0.000    0.000    0.000    0.000 utils.py:42(one_hot_encode_sequence)\n",
      "       40    0.000    0.000    0.000    0.000 utils.py:525(__init__)\n",
      "       40    0.000    0.000    0.000    0.000 utils.py:529(__getitem__)\n",
      "       10    0.000    0.000    0.000    0.000 utils.py:63(is_dask_collection)\n",
      "       90    0.000    0.000    0.000    0.000 utils.py:73(is_duck_array)\n",
      "       50    0.000    0.000    0.000    0.000 utils.py:826(drop_dims_from_indexers)\n",
      "       10    0.000    0.000    0.000    0.000 utils.py:89(is_duck_dask_array)\n",
      "      170    0.000    0.000    0.000    0.000 variable.py:1022(<genexpr>)\n",
      "       20    0.000    0.000    0.000    0.000 variable.py:183(_maybe_wrap_data)\n",
      "       60    0.000    0.000    0.000    0.000 variable.py:218(as_compatible_data)\n",
      "       10    0.000    0.000    0.000    0.000 variable.py:243(convert_non_numpy_type)\n",
      "       10    0.000    0.000    0.000    0.000 variable.py:2636(__init__)\n",
      "       10    0.000    0.000    0.000    0.000 variable.py:2692(_finalize_indexing_result)\n",
      "       20    0.000    0.000    0.000    0.000 variable.py:287(_as_array_or_item)\n",
      "       60    0.000    0.000    0.001    0.000 variable.py:336(__init__)\n",
      "       80    0.000    0.000    0.000    0.000 variable.py:400(data)\n",
      "       20    0.000    0.000    0.000    0.000 variable.py:504(values)\n",
      "       50    0.000    0.000    0.000    0.000 variable.py:561(_item_key_to_tuple)\n",
      "       50    0.000    0.000    0.002    0.000 variable.py:567(_broadcast_indexes)\n",
      "      170    0.000    0.000    0.000    0.000 variable.py:592(<genexpr>)\n",
      "      170    0.000    0.000    0.000    0.000 variable.py:597(<genexpr>)\n",
      "      170    0.000    0.000    0.000    0.000 variable.py:601(<genexpr>)\n",
      "       50    0.000    0.000    0.001    0.000 variable.py:626(_broadcast_indexes_basic)\n",
      "      140    0.000    0.000    0.000    0.000 variable.py:627(<genexpr>)\n",
      "       50    0.000    0.000    0.006    0.000 variable.py:753(__getitem__)\n",
      "       40    0.000    0.000    0.001    0.000 variable.py:775(_finalize_indexing_result)\n",
      "       10    0.000    0.000    0.000    0.000 variable.py:854(encoding)\n",
      "       20    0.000    0.000    0.000    0.000 variable.py:861(encoding)\n",
      "       40    0.000    0.000    0.001    0.000 variable.py:913(_replace)\n",
      "       50    0.000    0.000    0.007    0.000 variable.py:990(isel)\n",
      "        6    0.000    0.000    0.000    0.000 zmqstream.py:538(receiving)\n",
      "        3    0.000    0.000    0.000    0.000 zmqstream.py:542(sending)\n",
      "        3    0.000    0.000    0.000    0.000 zmqstream.py:556(_run_callback)\n",
      "        3    0.000    0.000    0.001    0.000 zmqstream.py:583(_handle_events)\n",
      "        3    0.000    0.000    0.000    0.000 zmqstream.py:624(_handle_recv)\n",
      "        3    0.000    0.000    0.000    0.000 zmqstream.py:663(_rebuild_io_state)\n",
      "        3    0.000    0.000    0.000    0.000 zmqstream.py:686(_update_handler)\n",
      "        1    0.000    0.000    0.000    0.000 zmqstream.py:694(<lambda>)\n",
      "       20    0.000    0.000    0.000    0.000 {built-in method __new__ of type object at 0x55d31ce48d40}\n",
      "      176    0.000    0.000    0.000    0.000 {built-in method _abc._abc_instancecheck}\n",
      "       63    0.000    0.000    0.000    0.000 {built-in method _abc._abc_subclasscheck}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method _asyncio.get_running_loop}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method _contextvars.copy_context}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method _heapq.heappush}\n",
      "       80    0.000    0.000    0.000    0.000 {built-in method _imp.acquire_lock}\n",
      "       10    0.000    0.000    0.000    0.000 {built-in method _imp.find_frozen}\n",
      "       10    0.000    0.000    0.000    0.000 {built-in method _imp.is_builtin}\n",
      "       80    0.000    0.000    0.000    0.000 {built-in method _imp.release_lock}\n",
      "       11    0.000    0.000    0.000    0.000 {built-in method _thread.allocate_lock}\n",
      "       20    0.000    0.000    0.000    0.000 {built-in method _thread.get_ident}\n",
      "       10    0.000    0.000    0.000    0.000 {built-in method _weakref._remove_dead_weakref}\n",
      "       86    0.000    0.000    0.000    0.000 {built-in method builtins.all}\n",
      "      125    0.000    0.000    0.000    0.000 {built-in method builtins.any}\n",
      "      2/1    0.000    0.000    0.023    0.023 {built-in method builtins.exec}\n",
      "      106    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\n",
      "  817/717    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}\n",
      "        6    0.000    0.000    0.000    0.000 {built-in method builtins.hash}\n",
      "2752/2746    0.001    0.000    0.001    0.000 {built-in method builtins.isinstance}\n",
      "      153    0.000    0.000    0.000    0.000 {built-in method builtins.issubclass}\n",
      "        3    0.000    0.000    0.000    0.000 {built-in method builtins.iter}\n",
      "  991/951    0.000    0.000    0.000    0.000 {built-in method builtins.len}\n",
      "       10    0.000    0.000    0.000    0.000 {built-in method builtins.locals}\n",
      "       26    0.000    0.000    0.000    0.000 {built-in method builtins.max}\n",
      "       22    0.000    0.000    0.000    0.000 {built-in method builtins.min}\n",
      "       11    0.000    0.000    0.002    0.000 {built-in method builtins.next}\n",
      "       20    0.000    0.000    0.000    0.000 {built-in method builtins.print}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method math.ceil}\n",
      "    78/68    0.000    0.000    0.001    0.000 {built-in method numpy.array}\n",
      "       20    0.000    0.000    0.000    0.000 {built-in method numpy.asanyarray}\n",
      "       54    0.000    0.000    0.000    0.000 {built-in method numpy.asarray}\n",
      "       30    0.000    0.000    0.000    0.000 {built-in method numpy.empty}\n",
      "       10    0.000    0.000    0.000    0.000 {built-in method numpy.frombuffer}\n",
      "       10    0.000    0.000    0.000    0.000 {built-in method numpy.lib.array_utils.normalize_axis_index}\n",
      "       10    0.000    0.000    0.000    0.000 {built-in method posix.getcwd}\n",
      "       42    0.000    0.000    0.000    0.000 {built-in method posix.getpid}\n",
      "      110    0.001    0.000    0.001    0.000 {built-in method posix.stat}\n",
      "        6    0.000    0.000    0.000    0.000 {built-in method time.monotonic}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method time.time}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method torch._C._log_api_usage_once}\n",
      "        5    0.000    0.000    0.000    0.000 {built-in method torch._ops.profiler._record_function_enter_new}\n",
      "        5    0.000    0.000    0.000    0.000 {built-in method torch._ops.profiler.}\n",
      "       40    0.000    0.000    0.000    0.000 {built-in method torch.as_tensor}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method torch.empty}\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method torch.randperm}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method torch.set_vital}\n",
      "       16    0.000    0.000    0.000    0.000 {built-in method torch.stack}\n",
      "        2    0.000    0.000    0.000    0.000 {method '__enter__' of '_thread.lock' objects}\n",
      "       60    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.RLock' objects}\n",
      "        7    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.lock' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {method '__exit__' of 'sqlite3.Connection' objects}\n",
      "        5    0.000    0.000    0.000    0.000 {method '__exit__' of 'torch._C.DisableTorchFunctionSubclass' objects}\n",
      "        4    0.000    0.000    0.000    0.000 {method 'acquire' of '_thread.lock' objects}\n",
      "        5    0.000    0.000    0.000    0.000 {method 'append' of 'collections.deque' objects}\n",
      "      396    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}\n",
      "       10    0.000    0.000    0.000    0.000 {method 'copy' of 'dict' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'decode' of 'bytes' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "       11    0.000    0.000    0.000    0.000 {method 'encode' of 'str' objects}\n",
      "       20    0.000    0.000    0.000    0.000 {method 'end' of 're.Match' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'execute' of 'sqlite3.Connection' objects}\n",
      "       62    0.000    0.000    0.000    0.000 {method 'extend' of 'list' objects}\n",
      "       10    0.000    0.000    0.000    0.000 {method 'format' of 'str' objects}\n",
      "       40    0.000    0.000    0.000    0.000 {method 'get' of '_contextvars.ContextVar' objects}\n",
      "      314    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}\n",
      "       20    0.000    0.000    0.000    0.000 {method 'group' of 're.Match' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'item' of 'torch._C.TensorBase' objects}\n",
      "      274    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}\n",
      "        3    0.000    0.000    0.000    0.000 {method 'items' of 'mappingproxy' objects}\n",
      "      550    0.000    0.000    0.000    0.000 {method 'join' of 'str' objects}\n",
      "       65    0.000    0.000    0.000    0.000 {method 'keys' of 'dict' objects}\n",
      "       20    0.000    0.000    0.000    0.000 {method 'match' of 're.Pattern' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {method 'poll' of 'select.epoll' objects}\n",
      "       10    0.000    0.000    0.000    0.000 {method 'pop' of 'dict' objects}\n",
      "       10    0.000    0.000    0.000    0.000 {method 'pop' of 'list' objects}\n",
      "        6    0.000    0.000    0.000    0.000 {method 'popleft' of 'collections.deque' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'random_' of 'torch._C.TensorBase' objects}\n",
      "       40    0.000    0.000    0.000    0.000 {method 'reduce' of 'numpy.ufunc' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'release' of '_thread.lock' objects}\n",
      "       10    0.000    0.000    0.000    0.000 {method 'remove' of 'list' objects}\n",
      "      150    0.000    0.000    0.000    0.000 {method 'rpartition' of 'str' objects}\n",
      "     1100    0.000    0.000    0.000    0.000 {method 'rstrip' of 'str' objects}\n",
      "        3    0.000    0.000    0.001    0.000 {method 'run' of '_contextvars.Context' objects}\n",
      "       20    0.000    0.000    0.000    0.000 {method 'search' of 're.Pattern' objects}\n",
      "       70    0.000    0.000    0.000    0.000 {method 'split' of 'str' objects}\n",
      "       90    0.000    0.000    0.000    0.000 {method 'startswith' of 'str' objects}\n",
      "       40    0.000    0.000    0.000    0.000 {method 'sum' of 'numpy.ndarray' objects}\n",
      "       16    0.000    0.000    0.000    0.000 {method 'to' of 'torch._C.TensorBase' objects}\n",
      "        5    0.000    0.000    0.000    0.000 {method 'translate' of 'str' objects}\n",
      "       20    0.000    0.000    0.000    0.000 {method 'update' of 'dict' objects}\n",
      "        6    0.000    0.000    0.000    0.000 {method 'upper' of 'str' objects}\n",
      "      175    0.000    0.000    0.000    0.000 {method 'values' of 'dict' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'values' of 'mappingproxy' objects}\n",
      "       40    0.000    0.000    0.000    0.000 {method 'write' of '_io.StringIO' objects}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cProfile\n",
    "\n",
    "code = '''\n",
    "for i, batch in enumerate(meta_train_dl.data):\n",
    "    print(f\"Meta Batch {i}:\")\n",
    "    for key, tensor in batch.items():\n",
    "        print(f\"  {key}: shape {tensor.shape}\")\n",
    "'''\n",
    "\n",
    "cProfile.run(code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22314258-3a2f-4958-8a77-fbd84cdc5b28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[10.],\n",
       "        [ 0.],\n",
       "        [ 0.]],\n",
       "\n",
       "       [[ 0.],\n",
       "        [20.],\n",
       "        [20.]],\n",
       "\n",
       "       [[ 0.],\n",
       "        [20.],\n",
       "        [20.]]], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata1.varp['hic_contacts'].data.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e176f52d-c269-4cdc-8e58-e5ce79ff54b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T',\n",
       " '__abs__',\n",
       " '__add__',\n",
       " '__and__',\n",
       " '__array__',\n",
       " '__array_function__',\n",
       " '__array_namespace__',\n",
       " '__array_priority__',\n",
       " '__array_ufunc__',\n",
       " '__bool__',\n",
       " '__class__',\n",
       " '__complex__',\n",
       " '__dask_tokenize__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__divmod__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__float__',\n",
       " '__floordiv__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__iadd__',\n",
       " '__iand__',\n",
       " '__ifloordiv__',\n",
       " '__ilshift__',\n",
       " '__imatmul__',\n",
       " '__imod__',\n",
       " '__imul__',\n",
       " '__index__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__int__',\n",
       " '__invert__',\n",
       " '__ior__',\n",
       " '__ipow__',\n",
       " '__irshift__',\n",
       " '__isub__',\n",
       " '__itruediv__',\n",
       " '__ixor__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lshift__',\n",
       " '__lt__',\n",
       " '__matmul__',\n",
       " '__metaclass__',\n",
       " '__mod__',\n",
       " '__module__',\n",
       " '__mul__',\n",
       " '__ne__',\n",
       " '__neg__',\n",
       " '__new__',\n",
       " '__or__',\n",
       " '__pos__',\n",
       " '__pow__',\n",
       " '__radd__',\n",
       " '__rand__',\n",
       " '__rdivmod__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__rfloordiv__',\n",
       " '__rlshift__',\n",
       " '__rmatmul__',\n",
       " '__rmod__',\n",
       " '__rmul__',\n",
       " '__ror__',\n",
       " '__rpow__',\n",
       " '__rrshift__',\n",
       " '__rshift__',\n",
       " '__rsub__',\n",
       " '__rtruediv__',\n",
       " '__rxor__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__slots__',\n",
       " '__str__',\n",
       " '__sub__',\n",
       " '__subclasshook__',\n",
       " '__truediv__',\n",
       " '__weakref__',\n",
       " '__xor__',\n",
       " '_cache',\n",
       " '_make_shallow_copy_of',\n",
       " '_prune',\n",
       " '_reduce',\n",
       " '_reduce_calc',\n",
       " '_reduce_return',\n",
       " '_repr_html_',\n",
       " '_sort_indices',\n",
       " '_str_impl',\n",
       " '_sum_duplicates',\n",
       " '_to_scalar',\n",
       " '_tocsr',\n",
       " 'all',\n",
       " 'amax',\n",
       " 'amin',\n",
       " 'any',\n",
       " 'asformat',\n",
       " 'astype',\n",
       " 'broadcast_to',\n",
       " 'clip',\n",
       " 'conj',\n",
       " 'coords',\n",
       " 'copy',\n",
       " 'data',\n",
       " 'density',\n",
       " 'dot',\n",
       " 'dtype',\n",
       " 'enable_caching',\n",
       " 'fill_value',\n",
       " 'flatten',\n",
       " 'format',\n",
       " 'from_iter',\n",
       " 'from_numpy',\n",
       " 'from_scipy_sparse',\n",
       " 'imag',\n",
       " 'isinf',\n",
       " 'isnan',\n",
       " 'linear_loc',\n",
       " 'max',\n",
       " 'maybe_densify',\n",
       " 'mean',\n",
       " 'min',\n",
       " 'nbytes',\n",
       " 'ndim',\n",
       " 'nnz',\n",
       " 'nonzero',\n",
       " 'prod',\n",
       " 'real',\n",
       " 'reduce',\n",
       " 'reshape',\n",
       " 'resize',\n",
       " 'round',\n",
       " 'round_',\n",
       " 'shape',\n",
       " 'size',\n",
       " 'squeeze',\n",
       " 'std',\n",
       " 'sum',\n",
       " 'swapaxes',\n",
       " 'to_scipy_sparse',\n",
       " 'tocsc',\n",
       " 'tocsr',\n",
       " 'todense',\n",
       " 'transpose',\n",
       " 'var']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(adata1.varp['hic_contacts'].data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b80ad40-b08c-4f21-b70e-283afb4245d7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dfssfd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdfssfd\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dfssfd' is not defined"
     ]
    }
   ],
   "source": [
    "dfssfd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42235987-9521-409e-86dc-a505111d1409",
   "metadata": {},
   "outputs": [],
   "source": [
    "import crandata\n",
    "import importlib\n",
    "crandata = importlib.reload(crandata)\n",
    "crandata.chrom_io = importlib.reload(crandata.chrom_io)\n",
    "crandata.crandata = importlib.reload(crandata.crandata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133aed5e-5c51-4d4c-9b2f-18813365c89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import crandata\n",
    "import os\n",
    "\n",
    "genome_path = '/allen/programs/celltypes/workgroups/rnaseqanalysis/EvoGen/Team/Matthew/genome/onehots/mouse'\n",
    "fasta_file = os.path.join(genome_path,'mouse.fa')\n",
    "chrom_sizes = os.path.join(genome_path,'mouse.fa.sizes')\n",
    "annotation_gtf_file = os.path.join(genome_path,'mouse.annotation.gtf')\n",
    "\n",
    "genome = crandata.Genome(fasta_file, chrom_sizes, annotation_gtf_file)\n",
    "\n",
    "# Set parameters for binning.\n",
    "WINDOW_SIZE = 2114\n",
    "OFFSET = WINDOW_SIZE // 2  # e.g., 50% overlap\n",
    "N_THRESHOLD = 0.3\n",
    "\n",
    "# Optionally specify an output path for the BED file.\n",
    "OUTPUT_BED = os.path.join(genome_path, \"binned_genome.bed\")\n",
    "\n",
    "# Generate bins and optionally write to disk.\n",
    "binned_df = crandata.bin_genome(genome, WINDOW_SIZE, OFFSET, n_threshold=N_THRESHOLD, output_path=OUTPUT_BED)\n",
    "\n",
    "print(\"Filtered bins:\")\n",
    "print(binned_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fbd99d-12d5-43c0-a1c4-96bfe68a92c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bigwigs_dir = '/allen/programs/celltypes/workgroups/rnaseqanalysis/EvoGen/SpinalCord/manuscript/ATAC/mouse/Group_bigwig/'\n",
    "n_bins = WINDOW_SIZE//50\n",
    "\n",
    "adata = crandata.chrom_io.import_bigwigs(\n",
    "    bigwigs_folder=bigwigs_dir,\n",
    "    regions_file=OUTPUT_BED,\n",
    "    backed_path='/home/matthew.schmitz/Matthew/mouse_spc_test.h5',\n",
    "    target_region_width=WINDOW_SIZE,\n",
    "    chromsizes_file=chrom_sizes,\n",
    "    n_bins=n_bins   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c999f883-8f01-4ddb-8f93-2d85691f4f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907d3827-0f78-4a6d-8e05-0a212bb1ff93",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.X[0,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f42942-cc49-4e05-8f0c-ae283d396106",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33821977-ebe5-45fd-877a-81cba6793751",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217d9613-3da5-40ef-8e2a-449843d4cb92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "adata = crandata.crandata.CrAnData.from_h5('/home/matthew.schmitz/Matthew/mouse_spc_test.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5616f7de-34a3-48bc-9ba3-a1cb5817fd2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d7baae-48c8-4c5a-a82a-5a1fb7b54064",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40515d7-6174-415d-82cc-a8784249510e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f70292f-f088-4e9d-a127-4736bb591964",
   "metadata": {},
   "outputs": [],
   "source": [
    "import crandata\n",
    "import os\n",
    "import crested\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b454e2de-689f-432e-9621-4d88f73e3b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "genomes = {}\n",
    "beds = {}\n",
    "chromsizes_files = {}\n",
    "bed_files = {}\n",
    "species = ['mouse','human','macaque']\n",
    "\n",
    "WINDOW_SIZE = 2114\n",
    "OFFSET = WINDOW_SIZE // 2  # e.g., 50% overlap\n",
    "N_THRESHOLD = 0.3\n",
    "n_bins = WINDOW_SIZE//50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392bdeca-411d-47ea-a846-6c906784b46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in species:\n",
    "    genome_path = '/allen/programs/celltypes/workgroups/rnaseqanalysis/EvoGen/Team/Matthew/genome/onehots/'+s\n",
    "    fasta_file = os.path.join(genome_path,s+'.fa')\n",
    "    chrom_sizes = os.path.join(genome_path,s+'.fa.sizes')\n",
    "    annotation_gtf_file = os.path.join(genome_path,s+'.annotation.gtf')\n",
    "    chromsizes_files[s] = chrom_sizes\n",
    "    genome = crandata.Genome(fasta_file, chrom_sizes, annotation_gtf_file)\n",
    "    genomes[s] = genome\n",
    "    # Set parameters for binning.\n",
    "    \n",
    "    # Optionally specify an output path for the BED file.\n",
    "    OUTPUT_BED = os.path.join(genome_path, \"binned_genome.bed\")\n",
    "    bed_files[s] = OUTPUT_BED\n",
    "    # Generate bins and optionally write to disk.\n",
    "    # binned_df = crandata.bin_genome(genome, WINDOW_SIZE, OFFSET, n_threshold=N_THRESHOLD, output_path=OUTPUT_BED)\n",
    "    # print(\"Filtered bins:\")\n",
    "    # print(binned_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10492d8e-e22d-48a3-8139-6d5aadc02d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "adatas = {}\n",
    "\n",
    "for s in species:\n",
    "    bigwigs_dir = os.path.join('/allen/programs/celltypes/workgroups/rnaseqanalysis/EvoGen/SpinalCord/manuscript/ATAC',s,'Group_bigwig')\n",
    "    # adata = crandata.chrom_io.import_bigwigs(\n",
    "    #     bigwigs_folder=bigwigs_dir,\n",
    "    #     regions_file=bed_files[s],\n",
    "    #     backed_path='/home/matthew.schmitz/Matthew/'+s+'_spc_test.h5',\n",
    "    #     target_region_width=WINDOW_SIZE,\n",
    "    #     chromsizes_file=chromsizes_files[s],\n",
    "    #     n_bins=n_bins\n",
    "    # )\n",
    "    # adatas[s] = adata\n",
    "    adatas[s] = crandata.crandata.CrAnData.from_h5('/home/matthew.schmitz/Matthew/'+s+'_spc_test.h5')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963ce450-9ef0-4d38-92cc-59521099497c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "adatas['mouse'].uns['chunk_size'] = 512\n",
    "adatas['human'].uns['chunk_size'] = 512\n",
    "adatas['macaque'].uns['chunk_size'] = 512\n",
    "adatas['mouse'].var[\"chunk_index\"] = np.arange(adatas['mouse'].var.shape[0]) // 512\n",
    "adatas['human'].var[\"chunk_index\"] = np.arange(adatas['human'].var.shape[0]) // 512\n",
    "adatas['macaque'].var[\"chunk_index\"] = np.arange(adatas['macaque'].var.shape[0]) // 512\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b667671b-3508-4daf-a706-92651c186854",
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in adatas.keys():\n",
    "    crested.pp.train_val_test_split(\n",
    "        adatas[s], strategy=\"region\", val_size=0.1, test_size=0.1, random_state=42\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8de975-ee1e-49ca-af1f-eb43d3b688a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import crandata\n",
    "import importlib\n",
    "importlib.reload(crandata)\n",
    "importlib.reload(crandata.crandata)\n",
    "importlib.reload(crandata._anndatamodule)\n",
    "importlib.reload(crandata._dataloader)\n",
    "importlib.reload(crandata._dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9aaf99e-b31e-4f93-a15d-e6ca8aa65780",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_module = crandata._anndatamodule.MetaAnnDataModule(\n",
    "    adatas=list(adatas.values()),\n",
    "    genomes=list(genomes.values()),\n",
    "    data_sources={'y': 'X'},\n",
    "    in_memory=True,\n",
    "    random_reverse_complement=True,\n",
    "    max_stochastic_shift=10,\n",
    "    deterministic_shift=False,\n",
    "    shuffle_obs=False,\n",
    "    shuffle=True,\n",
    "    batch_size=32,    # small batch size for testing\n",
    "    epoch_size=1000000    # small epoch size for quick testing\n",
    ")\n",
    "\n",
    "# Setup the meta module for the \"fit\" stage (train/val)\n",
    "meta_module.setup(\"fit\")\n",
    "\n",
    "# Retrieve the training dataloader from the meta module and iterate over a couple of batches.\n",
    "meta_train_dl = meta_module.train_dataloader\n",
    "\n",
    "print(\"\\nIterating over a couple of training batches from MetaAnnDataModule:\")\n",
    "for i, batch in enumerate(tqdm(meta_train_dl.data)):\n",
    "    print(f\"Meta Batch {i}:\")\n",
    "    for key, tensor in batch.items():\n",
    "        print(f\"  {key}: shape {tensor.shape}\")\n",
    "    if i == 5:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268b4942-0c9a-41ed-aac2-ee695fe62493",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a11e2cb-b92b-4c02-bc40-886f67d2e8d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cProfile\n",
    "\n",
    "code = '''\n",
    "for i, batch in enumerate(meta_train_dl.data):\n",
    "    # print(f\"Meta Batch {i}:\")\n",
    "    # for key, tensor in batch.items():\n",
    "    #     print(f\"  {key}: shape {tensor.shape}\")\n",
    "    if i == 5:\n",
    "        break\n",
    "'''\n",
    "\n",
    "out = cProfile.run(code,sort=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e661681c-6d1e-4441-9878-c21d0505df51",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_architecture = crested.tl.zoo.chrombpnet(\n",
    "    seq_len=2114, num_classes=51\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6348c92d-cfce-4e39-8a7f-3df53b363b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "# Create your own configuration\n",
    "# I recommend trying this for peak regression with a weighted cosine mse log loss function\n",
    "optimizer = keras.optimizers.Adam(learning_rate=1e-3)\n",
    "loss = crested.tl.losses.CosineMSELogLoss(max_weight=100, multiplier=1)\n",
    "metrics = [\n",
    "    keras.metrics.MeanAbsoluteError(),\n",
    "    keras.metrics.MeanSquaredError(),\n",
    "    keras.metrics.CosineSimilarity(axis=1),\n",
    "    crested.tl.metrics.PearsonCorrelation(),\n",
    "    crested.tl.metrics.ConcordanceCorrelationCoefficient(),\n",
    "    crested.tl.metrics.PearsonCorrelationLog(),\n",
    "    crested.tl.metrics.ZeroPenaltyMetric(),\n",
    "]\n",
    "\n",
    "alternative_config = crested.tl.TaskConfig(optimizer, loss, metrics)\n",
    "print(alternative_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b3716a-4a11-418e-9aad-6778019c0f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = crested.tl.Crested(\n",
    "    data=datamodule,\n",
    "    model=model_architecture,\n",
    "    config=alternative_config,\n",
    "    project_name=\"mouse_biccn\",  # change to your liking\n",
    "    run_name=\"basemodel\",  # change to your liking\n",
    "    logger=\"wandb\",  # or None, 'dvc', 'tensorboard'\n",
    "    seed=7,  # For reproducibility\n",
    ")\n",
    "# train the model\n",
    "trainer.fit(\n",
    "    epochs=60,\n",
    "    learning_rate_reduce_patience=3,\n",
    "    early_stopping_patience=6,\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crested",
   "language": "python",
   "name": "crested"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
