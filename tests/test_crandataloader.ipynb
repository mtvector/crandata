{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be832b9f-8fe5-4fee-bbef-c39648805b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import crandata\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9eee12c6-6743-4f06-af25-ebfffd6a9c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = xr.DataArray(np.arange(20).reshape(4, 5), dims=[\"obs\", \"var\"])\n",
    "obsm = {\"embedding\": xr.DataArray(np.random.rand(4, 2), dims=[\"obs\", \"other\"])}\n",
    "varm = {\"feature\": xr.DataArray(np.random.rand(5, 3), dims=[\"var\", \"other\"])}\n",
    "layers = {\"layer1\": X.copy()}\n",
    "varp = {\"contacts\": xr.DataArray(np.random.rand(5, 5), dims=[\"var_0\", \"var_1\"])}\n",
    "obsp = {\"adj\": xr.DataArray(np.random.rand(4, 4), dims=[\"obs_0\", \"obs_1\"])}\n",
    "data = crandata.crandata.CrAnData(\n",
    "    X, uns={\"extra\": \"test\"},\n",
    "    obsm=obsm, varm=varm, layers=layers, varp=varp, obsp=obsp\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a825901-0e9e-4fba-8703-1b2b79f66f50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CrAnData (primary: 'X') with axes: obs=4 (in-memory), var=5 (in-memory)\n",
       "  X: [obs=4, var=5] (in-memory)\n",
       "  obs: None\n",
       "  var: None\n",
       "  uns: {'extra': 'test'}\n",
       "  obsm: {'embedding': <xarray.DataArray (obs: 4, other: 2)> Size: 64B\n",
       "array([[0.22985535, 0.94814156],\n",
       "       [0.64438283, 0.6637138 ],\n",
       "       [0.28006699, 0.77574243],\n",
       "       [0.48166066, 0.95720116]])\n",
       "Dimensions without coordinates: obs, other}\n",
       "  varm: {'feature': <xarray.DataArray (var: 5, other: 3)> Size: 120B\n",
       "array([[0.01566936, 0.55565974, 0.49988154],\n",
       "       [0.60603383, 0.11160247, 0.25562868],\n",
       "       [0.63229154, 0.1040184 , 0.35389713],\n",
       "       [0.68509591, 0.76481753, 0.00623495],\n",
       "       [0.35098796, 0.68921427, 0.57629274]])\n",
       "Dimensions without coordinates: var, other}\n",
       "  layers: {'layer1': <xarray.DataArray (obs: 4, var: 5)> Size: 160B\n",
       "array([[ 0,  1,  2,  3,  4],\n",
       "       [ 5,  6,  7,  8,  9],\n",
       "       [10, 11, 12, 13, 14],\n",
       "       [15, 16, 17, 18, 19]])\n",
       "Dimensions without coordinates: obs, var}\n",
       "  varp: {'contacts': <xarray.DataArray (var_0: 5, var_1: 5)> Size: 200B\n",
       "array([[0.71982781, 0.30602275, 0.09200329, 0.26136994, 0.74084345],\n",
       "       [0.24329978, 0.54895508, 0.73842762, 0.18561541, 0.89249553],\n",
       "       [0.89136555, 0.52529877, 0.33844189, 0.99189918, 0.51327532],\n",
       "       [0.4860199 , 0.73794853, 0.87486702, 0.46243582, 0.59864032],\n",
       "       [0.67833109, 0.00462386, 0.73207337, 0.87512033, 0.24916745]])\n",
       "Dimensions without coordinates: var_0, var_1}\n",
       "  obsp: {'adj': <xarray.DataArray (obs_0: 4, obs_1: 4)> Size: 128B\n",
       "array([[0.56993903, 0.49189215, 0.86144571, 0.0269638 ],\n",
       "       [0.07883406, 0.47662793, 0.04768389, 0.42385208],\n",
       "       [0.37473628, 0.22976564, 0.84394636, 0.6075896 ],\n",
       "       [0.77688691, 0.86339817, 0.06603571, 0.91318767]])\n",
       "Dimensions without coordinates: obs_0, obs_1}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94acffde-a523-4bc6-9fd7-d6c0487fbe02",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 13819.78it/s]\n",
      "\u001b[32m2025-03-16 18:13:14.666\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcrandata.chrom_io\u001b[0m:\u001b[36mimport_bigwigs\u001b[0m:\u001b[36m290\u001b[0m - \u001b[1mExtracting values from 2 bigWig files...\u001b[0m\n",
      "2it [00:00, 102.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added Hi-C contact data to adata.varp['hic_contacts']:\n",
      "Shape: (3, 3, 1)\n",
      "<xarray.DataArray (var: 3, var_target: 3, obs: 1)> Size: 140B\n",
      "<COO: shape=(3, 3, 1), dtype=float32, nnz=5, fill_value=0.0>\n",
      "Coordinates:\n",
      "  * var         (var) <U12 144B 'chr1:100-200' 'chr1:300-400' 'chr1:350-450'\n",
      "  * var_target  (var_target) <U12 144B 'chr1:100-200' ... 'chr1:350-450'\n",
      "  * obs         (obs) <U5 20B 'test2'\n",
      "\n",
      "Directory contents: ['beds', 'bigwigs', 'chrom.sizes', 'consensus.bed', 'chrom_data.h5', 'test2.bedp', 'adata.h5']\n",
      "\n",
      "Loaded CrAnData from HDF5:\n",
      "CrAnData (primary: 'X') with axes: var=3 (backed), obs=2 (backed), seq_len=100 (backed)\n",
      "  X: [var=3, obs=2, seq_len=100] (backed)\n",
      "  obs: {'file_path': array(['/scratch/fast/46994/tmp7ojawwdz/bigwigs/test.bw',\n",
      "       '/scratch/fast/46994/tmp7ojawwdz/bigwigs/test2.bw'], dtype='<U48'), 'obs': <xarray.DataArray (obs: 2)> Size: 16B\n",
      "array([b'test', b'test2'], dtype=object)\n",
      "Dimensions without coordinates: obs}\n",
      "  var: {'chr': array(['chr1', 'chr1', 'chr1'], dtype='<U4'), 'chunk_index': array([0, 0, 0]), 'end': array([200, 400, 450]), 'region': array(['chr1:100-200', 'chr1:300-400', 'chr1:350-450'], dtype='<U12'), 'start': array([100, 300, 350])}\n",
      "  uns: {'params': {'chunk_size': np.int64(512), 'max_stochastic_shift': np.int64(0), 'shifted_region_width': np.int64(100), 'target_region_width': np.int64(100)}}\n",
      "  obsm: {'gex': <xarray.DataArray (obs: 2, genes: 50)> Size: 800B\n",
      "array([[-0.23879437, -1.08887227,  0.06602372,  0.54788324, -1.12349605,\n",
      "        -1.20276   ,  0.15680968,  0.45548021, -0.06176918,  2.19262141,\n",
      "         0.57244452,  0.36229504, -0.92175291,  0.89036909,  0.87277268,\n",
      "        -1.13472371, -1.54570445,  0.31360654, -0.84309777, -0.1405657 ,\n",
      "         1.4777621 , -0.5143223 ,  1.04393709,  0.19694517, -0.88447453,\n",
      "        -0.04389964, -0.36293939, -2.11543302, -0.25391938, -0.51230338,\n",
      "        -0.14340731,  0.2149469 ,  0.40005761, -0.55502966, -0.22444829,\n",
      "        -0.38668334, -1.06580225,  0.54629156,  0.53324549,  0.99155129,\n",
      "        -0.06329739, -1.05806214,  1.26813989,  0.96145299,  0.00526036,\n",
      "        -0.12081802, -2.05484266, -0.64800764,  2.50396486,  1.00724089],\n",
      "       [ 0.53449045, -1.72410904,  0.55033353, -0.34429976,  0.14354115,\n",
      "        -0.78117617,  0.37816021,  0.36304869,  0.67374657, -0.34402035,\n",
      "         0.63342277, -1.39156376,  1.39601095, -0.49010332,  0.2741214 ,\n",
      "         0.34529679,  0.07629658, -1.11726106,  1.0391378 ,  1.7785206 ,\n",
      "         0.46447247,  0.21273008,  0.25624276,  1.31522705, -0.0355571 ,\n",
      "        -0.36479539,  0.63147328, -1.1583503 , -0.3875026 ,  0.78971986,\n",
      "         0.47371314,  0.2156213 , -0.69784589, -0.38201923,  0.47512054,\n",
      "        -0.57646194, -0.59676171,  0.72280077,  0.30557527,  1.96293125,\n",
      "        -0.79412495, -1.07634703, -0.80737132, -1.39823192,  0.03953453,\n",
      "        -0.70630156, -0.27095703,  1.15722817,  0.6625415 , -1.32480907]])\n",
      "Dimensions without coordinates: obs, genes}\n",
      "  varm: None\n",
      "  layers: None\n",
      "  varp: {'hic_contacts': <xarray.DataArray (var: 3, var_target: 3, obs: 1)> Size: 140B\n",
      "<COO: shape=(3, 3, 1), dtype=float32, nnz=5, fill_value=0.0>\n",
      "Dimensions without coordinates: var, var_target, obs}\n",
      "obs:\n",
      "{'file_path': array(['/scratch/fast/46994/tmp7ojawwdz/bigwigs/test.bw',\n",
      "       '/scratch/fast/46994/tmp7ojawwdz/bigwigs/test2.bw'], dtype='<U48'), 'obs': <xarray.DataArray (obs: 2)> Size: 16B\n",
      "array([b'test', b'test2'], dtype=object)\n",
      "Dimensions without coordinates: obs}\n",
      "var:\n",
      "{'chr': array(['chr1', 'chr1', 'chr1'], dtype='<U4'), 'chunk_index': array([0, 0, 0]), 'end': array([200, 400, 450]), 'region': array(['chr1:100-200', 'chr1:300-400', 'chr1:350-450'], dtype='<U12'), 'start': array([100, 300, 350])}\n",
      "varp keys: ['hic_contacts']\n",
      "Hi-C contact data shape: (3, 3, 1)\n",
      "<xarray.DataArray (var: 3, var_target: 3, obs: 1)> Size: 140B\n",
      "<COO: shape=(3, 3, 1), dtype=float32, nnz=5, fill_value=0.0>\n",
      "Dimensions without coordinates: var, var_target, obs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'sum'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 157\u001b[0m\n\u001b[1;32m    142\u001b[0m meta_module \u001b[38;5;241m=\u001b[39m crandata\u001b[38;5;241m.\u001b[39m_anndatamodule\u001b[38;5;241m.\u001b[39mMetaAnnDataModule(\n\u001b[1;32m    143\u001b[0m     adatas\u001b[38;5;241m=\u001b[39m[adata1, adata2],\n\u001b[1;32m    144\u001b[0m     genomes\u001b[38;5;241m=\u001b[39m[dummy_genome, dummy_genome],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    153\u001b[0m     epoch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m    \u001b[38;5;66;03m# small epoch size for quick testing\u001b[39;00m\n\u001b[1;32m    154\u001b[0m )\n\u001b[1;32m    156\u001b[0m \u001b[38;5;66;03m# Setup the meta module for the \"fit\" stage (train/val)\u001b[39;00m\n\u001b[0;32m--> 157\u001b[0m \u001b[43mmeta_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetup\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfit\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;66;03m# Retrieve the training dataloader from the meta module and iterate over a couple of batches.\u001b[39;00m\n\u001b[1;32m    160\u001b[0m meta_train_dl \u001b[38;5;241m=\u001b[39m meta_module\u001b[38;5;241m.\u001b[39mtrain_dataloader\n",
      "File \u001b[0;32m/allen/programs/celltypes/workgroups/rnaseqanalysis/EvoGen/Team/Matthew/code/crandata/crandata/_anndatamodule.py:311\u001b[0m, in \u001b[0;36mMetaAnnDataModule.setup\u001b[0;34m(self, stage)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m adata, genome \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madatas, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenomes):\n\u001b[1;32m    310\u001b[0m     args \u001b[38;5;241m=\u001b[39m dataset_args(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 311\u001b[0m     \u001b[43mset_stage_sample_probs\u001b[49m\u001b[43m(\u001b[49m\u001b[43madata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    312\u001b[0m     ds_train \u001b[38;5;241m=\u001b[39m AnnDataset(adata\u001b[38;5;241m=\u001b[39madata, genome\u001b[38;5;241m=\u001b[39mgenome, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m    313\u001b[0m     train_datasets\u001b[38;5;241m.\u001b[39mappend(ds_train)\n",
      "File \u001b[0;32m/allen/programs/celltypes/workgroups/rnaseqanalysis/EvoGen/Team/Matthew/code/crandata/crandata/_anndatamodule.py:27\u001b[0m, in \u001b[0;36mset_stage_sample_probs\u001b[0;34m(adata, stage)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_probs\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m adata\u001b[38;5;241m.\u001b[39mvar:\n\u001b[1;32m     26\u001b[0m     adata\u001b[38;5;241m.\u001b[39mvar[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_probs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m\n\u001b[0;32m---> 27\u001b[0m adata\u001b[38;5;241m.\u001b[39mvar[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_probs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m adata\u001b[38;5;241m.\u001b[39mvar[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_probs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m/\u001b[39m \u001b[43madata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvar\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain_probs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m()\n\u001b[1;32m     28\u001b[0m sample_probs[mask] \u001b[38;5;241m=\u001b[39m adata\u001b[38;5;241m.\u001b[39mvar[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_probs\u001b[39m\u001b[38;5;124m\"\u001b[39m][mask]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m     29\u001b[0m adata\u001b[38;5;241m.\u001b[39mvar[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample_probs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m sample_probs \u001b[38;5;241m/\u001b[39m sample_probs\u001b[38;5;241m.\u001b[39msum()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'float' object has no attribute 'sum'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyBigWig\n",
    "import importlib\n",
    "import xarray as xr\n",
    "import tqdm\n",
    "import copy\n",
    "\n",
    "import crandata\n",
    "crandata = importlib.reload(crandata)\n",
    "\n",
    "import crandata.chrom_io\n",
    "crandata.crandata = importlib.reload(crandata.crandata)\n",
    "crandata.chrom_io = importlib.reload(crandata.chrom_io)\n",
    "crandata._anndatamodule = importlib.reload(crandata._anndatamodule)\n",
    "crandata._dataloader = importlib.reload(crandata._dataloader)\n",
    "from crandata._anndatamodule import MetaAnnDataModule\n",
    "\n",
    "# Create temporary directories for beds, bigwigs, etc.\n",
    "temp_dir = tempfile.TemporaryDirectory()\n",
    "base_dir = Path(temp_dir.name)\n",
    "beds_dir = base_dir / \"beds\"\n",
    "bigwigs_dir = base_dir / \"bigwigs\"\n",
    "beds_dir.mkdir(exist_ok=True)\n",
    "bigwigs_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Create a chromsizes file\n",
    "chromsizes_file = base_dir / \"chrom.sizes\"\n",
    "with open(chromsizes_file, \"w\") as f:\n",
    "    f.write(\"chr1\\t1000\\n\")\n",
    "\n",
    "# Create two BED files (ClassA and ClassB)\n",
    "bed_data_A = pd.DataFrame({0: [\"chr1\", \"chr1\"],\n",
    "                           1: [100, 300],\n",
    "                           2: [200, 400]})\n",
    "bed_data_B = pd.DataFrame({0: [\"chr1\", \"chr1\"],\n",
    "                           1: [150, 350],\n",
    "                           2: [250, 450]})\n",
    "bed_file_A = beds_dir / \"ClassA.bed\"\n",
    "bed_file_B = beds_dir / \"ClassB.bed\"\n",
    "bed_data_A.to_csv(bed_file_A, sep=\"\\t\", header=False, index=False)\n",
    "bed_data_B.to_csv(bed_file_B, sep=\"\\t\", header=False, index=False)\n",
    "\n",
    "# Create a consensus BED file\n",
    "consensus = pd.DataFrame({0: [\"chr1\", \"chr1\", \"chr1\"],\n",
    "                          1: [100, 300, 350],\n",
    "                          2: [200, 400, 450]})\n",
    "consensus_file = base_dir / \"consensus.bed\"\n",
    "consensus.to_csv(consensus_file, sep=\"\\t\", header=False, index=False)\n",
    "\n",
    "# Create a bigWig file with a single chromosome region\n",
    "bigwig_file = bigwigs_dir / \"test.bw\"\n",
    "bw = pyBigWig.open(str(bigwig_file), \"w\")\n",
    "bw.addHeader([(\"chr1\", 1000)])\n",
    "bw.addEntries(chroms=[\"chr1\"], starts=[0], ends=[1000], values=[5.0])\n",
    "bw.close()\n",
    "\n",
    "bigwig_file = bigwigs_dir / \"test2.bw\"\n",
    "bw = pyBigWig.open(str(bigwig_file), \"w\")\n",
    "bw.addHeader([(\"chr1\", 1000)])\n",
    "bw.addEntries(chroms=[\"chr1\"], starts=[0], ends=[1000], values=[4.0])\n",
    "bw.close()\n",
    "\n",
    "# Set parameters for extraction\n",
    "target_region_width = 100\n",
    "backed_path = os.path.join(base_dir, \"chrom_data.h5\")\n",
    "\n",
    "# Create the CrAnData object from the bigWig files and consensus regions\n",
    "adata = crandata.chrom_io.import_bigwigs(\n",
    "    bigwigs_folder=bigwigs_dir,\n",
    "    regions_file=consensus_file,\n",
    "    backed_path=backed_path,\n",
    "    target_region_width=target_region_width,\n",
    "    chromsizes_file=chromsizes_file,  \n",
    ")\n",
    "\n",
    "# Ensure obsm is a dictionary before adding entries.\n",
    "if adata.obsm is None:\n",
    "    adata.obsm = {}\n",
    "\n",
    "# Add a random obsm entry\n",
    "adata.obsm['gex'] = xr.DataArray(np.random.randn(adata.n_obs, 50),\n",
    "                                 dims=['obs', 'genes'])\n",
    "\n",
    "# Create a synthetic BEDP file for Hi-C contacts and add contacts to adata.varp\n",
    "synthetic_bedp = pd.DataFrame({\n",
    "    0: [\"chr1\", \"chr1\"],\n",
    "    1: [100, 300],\n",
    "    2: [200, 400],\n",
    "    3: [\"chr1\", \"chr1\"],\n",
    "    4: [150, 350],\n",
    "    5: [250, 450],\n",
    "    6: [10, 20]\n",
    "})\n",
    "synthetic_bedp_file = base_dir / \"test2.bedp\"\n",
    "synthetic_bedp.to_csv(synthetic_bedp_file, sep=\"\\t\", header=False, index=False)\n",
    "\n",
    "from crandata.chrom_io import add_contact_strengths_to_varp\n",
    "contacts = add_contact_strengths_to_varp(adata, [str(synthetic_bedp_file)], key=\"hic_contacts\")\n",
    "\n",
    "print(\"Added Hi-C contact data to adata.varp['hic_contacts']:\")\n",
    "print(\"Shape:\", adata.varp[\"hic_contacts\"].shape)\n",
    "print(adata.varp[\"hic_contacts\"])\n",
    "\n",
    "# Write to HDF5 and load back.\n",
    "h5_path = os.path.join(base_dir, \"adata.h5\")\n",
    "adata.to_h5(h5_path)\n",
    "adata_loaded = crandata.crandata.CrAnData.from_h5(h5_path, backed=['X'])\n",
    "print(\"\\nDirectory contents:\", os.listdir(base_dir))\n",
    "print(\"\\nLoaded CrAnData from HDF5:\")\n",
    "print(adata_loaded)\n",
    "print(\"obs:\")\n",
    "print(adata_loaded.obs)\n",
    "print(\"var:\")\n",
    "print(adata_loaded.var)\n",
    "print(\"varp keys:\", list(adata_loaded.varp.keys()))\n",
    "if \"hic_contacts\" in adata_loaded.varp:\n",
    "    print(\"Hi-C contact data shape:\", adata_loaded.varp[\"hic_contacts\"].shape)\n",
    "    print(adata_loaded.varp[\"hic_contacts\"])\n",
    "\n",
    "# Create two copies of the loaded CrAnData (simulate two different datasets/species)\n",
    "adata1 = copy.deepcopy(adata_loaded)\n",
    "adata2 = copy.deepcopy(adata_loaded)\n",
    "# Ensure each has a 'split' column\n",
    "adata1.var[\"split\"] = \"train\"\n",
    "adata2.var[\"split\"] = \"train\"\n",
    "\n",
    "# Create a dummy FASTA file for the genome (with a single record for chr1)\n",
    "fasta_file = base_dir / \"chr1.fa\"\n",
    "with open(fasta_file, \"w\") as f:\n",
    "    f.write(\">chr1\\n\")\n",
    "    f.write(\"A\" * 1000 + \"\\n\")\n",
    "\n",
    "# Instead of passing a string, create a Genome object.\n",
    "from crandata._genome import Genome\n",
    "dummy_genome = Genome(str(fasta_file), chrom_sizes=str(chromsizes_file))\n",
    "\n",
    "# Instantiate MetaAnnDataModule with the two datasets and corresponding genomes.\n",
    "meta_module = crandata._anndatamodule.MetaAnnDataModule(\n",
    "    adatas=[adata1, adata2],\n",
    "    genomes=[dummy_genome, dummy_genome],\n",
    "    data_sources={'y': 'X', 'hic': 'varp/hic_contacts', 'gex': 'obsm/gex'},\n",
    "    in_memory=True,\n",
    "    random_reverse_complement=True,\n",
    "    max_stochastic_shift=5,\n",
    "    deterministic_shift=False,\n",
    "    shuffle_obs=True,\n",
    "    shuffle=True,\n",
    "    batch_size=3,    # small batch size for testing\n",
    "    epoch_size=10    # small epoch size for quick testing\n",
    ")\n",
    "\n",
    "# Setup the meta module for the \"fit\" stage (train/val)\n",
    "meta_module.setup(\"fit\")\n",
    "\n",
    "# Retrieve the training dataloader from the meta module and iterate over a couple of batches.\n",
    "meta_train_dl = meta_module.train_dataloader\n",
    "\n",
    "print(\"\\nIterating over a couple of training batches from MetaAnnDataModule:\")\n",
    "for i, batch in enumerate(tqdm.tqdm(meta_train_dl.data)):\n",
    "    print(f\"Meta Batch {i}:\")\n",
    "    for key, tensor in batch.items():\n",
    "        print(f\"  {key}: shape {tensor.shape}\")\n",
    "        # print(tensor)\n",
    "    # For quick testing, you can uncomment the following to break early:\n",
    "    # if i == 1:\n",
    "    #     break\n",
    "\n",
    "print(\"Final directory contents:\", os.listdir(base_dir))\n",
    "\n",
    "temp_dir.cleanup()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04edae4a-ab55-4704-a2ec-01e9c2fe9e5c",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'train_probs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43madata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvar\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain_probs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'train_probs'"
     ]
    }
   ],
   "source": [
    "adata.var['train_probs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f90c93f-9df3-4724-8d76-bba467e474d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata._propagate_missing_coordinates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7361e12-a505-47a7-9f2e-cb795365b522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CrAnData (primary: 'X') with axes: var=3 (backed), obs=2 (backed), seq_len=100 (backed)\n",
       "  X: [var=3, obs=2, seq_len=100] (backed)\n",
       "  obs:                                               file_path\n",
       "test    /scratch/fast/46987/tmpfckoy7a7/bigwigs/test.bw\n",
       "test2  /scratch/fast/46987/tmpfckoy7a7/bigwigs/test2.bw\n",
       "  var:              chrom  start  end  chunk_index   chr\n",
       "region                                           \n",
       "chr1:100-200  chr1    100  200            0  chr1\n",
       "chr1:300-400  chr1    300  400            0  chr1\n",
       "chr1:350-450  chr1    350  450            0  chr1\n",
       "  uns: {'params': {'chunk_size': np.int64(512), 'max_stochastic_shift': np.int64(0), 'shifted_region_width': np.int64(100), 'target_region_width': np.int64(100)}}\n",
       "  obsm: {'gex': <xarray.DataArray (obs: 2, genes: 50)> Size: 800B\n",
       "array([[-0.84286505, -0.3330085 ,  2.1528912 , -0.45353179,  0.780963  ,\n",
       "        -1.45020481, -1.88673658, -0.50893806,  0.45560893,  0.56886984,\n",
       "         1.43031937, -1.16437629, -0.69579686, -0.39076824,  0.61276765,\n",
       "        -0.52735368,  1.95101758,  1.16200718, -0.20836493, -0.73912338,\n",
       "        -1.20320082,  1.32667244, -0.7938558 ,  1.34612879, -0.60373997,\n",
       "        -0.03196049,  0.80343131,  0.59683474,  1.11228581, -0.54623635,\n",
       "        -0.37789913,  1.01473279,  0.57714221,  0.5896189 ,  0.52086344,\n",
       "         2.12883957,  1.39997232,  0.51079086,  1.14664977,  0.39205929,\n",
       "        -0.28683834,  0.41117144, -0.25462988,  0.01228398,  0.12508422,\n",
       "         0.34866234,  0.93331697, -0.18688004,  1.54426596,  1.88670555],\n",
       "       [ 0.98275884, -0.40867046,  0.05183996,  0.28182523,  0.52456516,\n",
       "        -0.310541  ,  0.58962746,  0.28615172,  0.79053783,  1.14855205,\n",
       "         0.71246403, -1.57925348,  0.48843752, -1.17618921, -1.26422567,\n",
       "        -2.42848051,  1.62718461,  0.73680574, -0.43240011, -0.54715365,\n",
       "         1.34444361, -0.17500193,  0.79753823, -0.97789536, -0.78870841,\n",
       "        -0.14892705,  0.34398737, -0.5050934 ,  0.71749261, -0.97414334,\n",
       "         1.85871521,  0.75535886, -0.53345532,  1.31392825,  0.74246691,\n",
       "         0.3854895 , -0.88959804,  0.23152768, -0.01891901, -0.76671576,\n",
       "         0.02917302,  0.00567134, -1.2083833 ,  1.22480662, -0.6308372 ,\n",
       "        -0.56633591, -1.08717338, -0.35581364,  0.03647114, -0.03679701]])\n",
       "Dimensions without coordinates: obs, genes}\n",
       "  varm: None\n",
       "  layers: None\n",
       "  varp: {'hic_contacts': <xarray.DataArray (var: 3, var_target: 3, obs: 1)> Size: 140B\n",
       "<COO: shape=(3, 3, 1), dtype=float32, nnz=5, fill_value=0.0>\n",
       "Coordinates:\n",
       "  * var         (var) <U12 144B 'chr1:100-200' 'chr1:300-400' 'chr1:350-450'\n",
       "  * var_target  (var_target) <U12 144B 'chr1:100-200' ... 'chr1:350-450'\n",
       "  * obs         (obs) <U5 20B 'test2'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dde843a-9bd9-4a0d-aa02-5ad3508d2e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, batch in enumerate(tqdm.tqdm(meta_train_dl.data)):\n",
    "    print(f\"Meta Batch {i}:\")\n",
    "    for key, tensor in batch.items():\n",
    "        print(f\"  {key}: shape {tensor.shape}\")\n",
    "        # print(tensor)\n",
    "    # For quick testing, you can uncomment the following to break early:\n",
    "    # if i == 1:\n",
    "    #     break\n",
    "\n",
    "print(\"Final directory contents:\", os.listdir(base_dir))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06f80a2-d874-4823-abaf-58f67726b16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch['sequence'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b4837c-5033-4e05-866f-e4f6a3340bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch['hic'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cf2013-0c20-4563-94d8-bf7c245a47d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.global_axis_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f1dd75-1fd4-437d-a720-3e7b2494d423",
   "metadata": {},
   "outputs": [],
   "source": [
    "fff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ebbd33-d888-4bee-a9b7-93743886288e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cProfile\n",
    "\n",
    "code = '''\n",
    "for i, batch in enumerate(meta_train_dl.data):\n",
    "    print(f\"Meta Batch {i}:\")\n",
    "    for key, tensor in batch.items():\n",
    "        print(f\"  {key}: shape {tensor.shape}\")\n",
    "'''\n",
    "\n",
    "cProfile.run(code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2eb058-5a2f-47e2-9bca-b79d494b1490",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f70292f-f088-4e9d-a127-4736bb591964",
   "metadata": {},
   "outputs": [],
   "source": [
    "import crandata\n",
    "import os\n",
    "import crested\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b454e2de-689f-432e-9621-4d88f73e3b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "genomes = {}\n",
    "beds = {}\n",
    "chromsizes_files = {}\n",
    "bed_files = {}\n",
    "species = ['mouse','human','macaque']\n",
    "\n",
    "WINDOW_SIZE = 2114\n",
    "OFFSET = WINDOW_SIZE // 2  # e.g., 50% overlap\n",
    "N_THRESHOLD = 0.3\n",
    "n_bins = WINDOW_SIZE//50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392bdeca-411d-47ea-a846-6c906784b46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in species:\n",
    "    genome_path = '/allen/programs/celltypes/workgroups/rnaseqanalysis/EvoGen/Team/Matthew/genome/onehots/'+s\n",
    "    fasta_file = os.path.join(genome_path,s+'.fa')\n",
    "    chrom_sizes = os.path.join(genome_path,s+'.fa.sizes')\n",
    "    annotation_gtf_file = os.path.join(genome_path,s+'.annotation.gtf')\n",
    "    chromsizes_files[s] = chrom_sizes\n",
    "    genome = crandata.Genome(fasta_file, chrom_sizes, annotation_gtf_file)\n",
    "    genomes[s] = genome\n",
    "    # Set parameters for binning.\n",
    "    \n",
    "    # Optionally specify an output path for the BED file.\n",
    "    OUTPUT_BED = os.path.join(genome_path, \"binned_genome.bed\")\n",
    "    bed_files[s] = OUTPUT_BED\n",
    "    # Generate bins and optionally write to disk.\n",
    "    # binned_df = crandata.bin_genome(genome, WINDOW_SIZE, OFFSET, n_threshold=N_THRESHOLD, output_path=OUTPUT_BED)\n",
    "    # print(\"Filtered bins:\")\n",
    "    # print(binned_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10492d8e-e22d-48a3-8139-6d5aadc02d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "adatas = {}\n",
    "\n",
    "for s in species:\n",
    "    # bigwigs_dir = os.path.join('/allen/programs/celltypes/workgroups/rnaseqanalysis/EvoGen/SpinalCord/manuscript/ATAC',s,'Group_bigwig')\n",
    "    # adata = crandata.chrom_io.import_bigwigs(\n",
    "    #     bigwigs_folder=bigwigs_dir,\n",
    "    #     regions_file=bed_files[s],\n",
    "    #     backed_path='/home/matthew.schmitz/Matthew/'+s+'_spc_test.h5',\n",
    "    #     target_region_width=WINDOW_SIZE,\n",
    "    #     chromsizes_file=chromsizes_files[s],\n",
    "    #     target = 'mean',\n",
    "    #     n_bins=n_bins\n",
    "    # )\n",
    "    # adatas[s] = adata\n",
    "    adatas[s] = crandata.crandata.CrAnData.from_h5('/home/matthew.schmitz/Matthew/'+s+'_spc_test.h5')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963ce450-9ef0-4d38-92cc-59521099497c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# adatas['mouse'].uns['chunk_size'] = 512\n",
    "# adatas['human'].uns['chunk_size'] = 512\n",
    "# adatas['macaque'].uns['chunk_size'] = 512\n",
    "# adatas['mouse'].var[\"chunk_index\"] = np.arange(adatas['mouse'].var.shape[0]) // 512\n",
    "# adatas['human'].var[\"chunk_index\"] = np.arange(adatas['human'].var.shape[0]) // 512\n",
    "# adatas['macaque'].var[\"chunk_index\"] = np.arange(adatas['macaque'].var.shape[0]) // 512\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b667671b-3508-4daf-a706-92651c186854",
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in adatas.keys():\n",
    "    crested.pp.train_val_test_split(\n",
    "        adatas[s], strategy=\"region\", val_size=0.1, test_size=0.1, random_state=42\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9aaf99e-b31e-4f93-a15d-e6ca8aa65780",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_module = crandata._anndatamodule.MetaAnnDataModule(\n",
    "    adatas=list(adatas.values()),\n",
    "    genomes=list(genomes.values()),\n",
    "    data_sources={'y': 'X'},\n",
    "    in_memory=False,\n",
    "    random_reverse_complement=True,\n",
    "    max_stochastic_shift=10,\n",
    "    deterministic_shift=False,\n",
    "    shuffle_obs=False, obs_alignment = 'intersect',\n",
    "    shuffle=True,\n",
    "    batch_size=32,    # small batch size for testing\n",
    "    epoch_size=1000000    # small epoch size for quick testing\n",
    ")\n",
    "\n",
    "# Setup the meta module for the \"fit\" stage (train/val)\n",
    "meta_module.setup(\"fit\")\n",
    "\n",
    "# Retrieve the training dataloader from the meta module and iterate over a couple of batches.\n",
    "meta_train_dl = meta_module.train_dataloader\n",
    "\n",
    "print(\"\\nIterating over a couple of training batches from MetaAnnDataModule:\")\n",
    "for i, batch in enumerate(tqdm(meta_train_dl.data)):\n",
    "    print(f\"Meta Batch {i}:\")\n",
    "    for key, tensor in batch.items():\n",
    "        print(f\"  {key}: shape {tensor.shape}\")\n",
    "    if i == 5:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de99d0b3-99e8-4a30-8cf4-b762a1247d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, batch in enumerate(tqdm(meta_train_dl.data)):\n",
    "    print(f\"Meta Batch {i}:\")\n",
    "    for key, tensor in batch.items():\n",
    "        print(f\"  {key}: shape {tensor.dtype}\")\n",
    "    if i == 5:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a11e2cb-b92b-4c02-bc40-886f67d2e8d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cProfile\n",
    "\n",
    "code = '''\n",
    "for i, batch in enumerate(meta_train_dl.data):\n",
    "    # print(f\"Meta Batch {i}:\")\n",
    "    # for key, tensor in batch.items():\n",
    "    #     print(f\"  {key}: shape {tensor.shape}\")\n",
    "    if i == 5:\n",
    "        break\n",
    "'''\n",
    "\n",
    "out = cProfile.run(code,sort=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e661681c-6d1e-4441-9878-c21d0505df51",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_architecture = crested.tl.zoo.simple_convnet(\n",
    "    seq_len=2114, num_classes=batch['y'].shape[1]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6348c92d-cfce-4e39-8a7f-3df53b363b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "# Create your own configuration\n",
    "# I recommend trying this for peak regression with a weighted cosine mse log loss function\n",
    "optimizer = keras.optimizers.Adam(learning_rate=1e-5)\n",
    "loss = crested.tl.losses.CosineMSELogLoss(max_weight=100, multiplier=1)\n",
    "loss = crested.tl.losses.PoissonLoss()\n",
    "\n",
    "metrics = [\n",
    "    keras.metrics.MeanAbsoluteError(),\n",
    "    # keras.metrics.MeanSquaredError(),\n",
    "    # keras.metrics.CosineSimilarity(axis=1),\n",
    "    crested.tl.metrics.PearsonCorrelation(),\n",
    "    # crested.tl.metrics.ConcordanceCorrelationCoefficient(),\n",
    "    # crested.tl.metrics.PearsonCorrelationLog(),\n",
    "    # crested.tl.metrics.ZeroPenaltyMetric(),\n",
    "]\n",
    "\n",
    "alternative_config = crested.tl.TaskConfig(optimizer, loss, metrics)\n",
    "print(alternative_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e5aeb3-5514-466c-b8c7-f04556666c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize some lazy model parameters *yawn*\n",
    "model_architecture(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b3716a-4a11-418e-9aad-6778019c0f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = crested.tl.Crested(\n",
    "    data=meta_module,\n",
    "    model=model_architecture,\n",
    "    config=alternative_config,\n",
    "    project_name=\"mouse_biccn\",  # change to your liking\n",
    "    run_name=\"basemodel\",  # change to your liking\n",
    "    logger=None,  # or None, 'dvc', 'tensorboard'\n",
    "    seed=7,  # For reproducibility\n",
    ")\n",
    "# train the model\n",
    "trainer.fit(\n",
    "    epochs=60,\n",
    "    learning_rate_reduce_patience=3,\n",
    "    early_stopping_patience=6,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9acd5a76-9f07-4525-8c6d-4b5f3ed12aae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crested",
   "language": "python",
   "name": "crested"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
